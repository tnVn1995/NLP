{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Categorization\n",
    "\n",
    "The dataset comes from sklearn fetch_20newsgroups datasets (Make more modification later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of topics from the dataset is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>686</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>665</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>664</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>658</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>653</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>649</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>642</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>636</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>634</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>634</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>633</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>631</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>624</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>623</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>617</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>609</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>581</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>508</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>503</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>414</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Target Label  Train Count  Test Count\n",
       "12          rec.sport.hockey          686         288\n",
       "11                 sci.crypt          665         297\n",
       "7     soc.religion.christian          664         310\n",
       "2              comp.graphics          658         295\n",
       "0            rec.motorcycles          653         316\n",
       "14            comp.windows.x          649         331\n",
       "18                 rec.autos          642         293\n",
       "3         rec.sport.baseball          636         315\n",
       "17  comp.sys.ibm.pc.hardware          634         329\n",
       "1            sci.electronics          634         322\n",
       "16              misc.forsale          633         326\n",
       "5      comp.sys.mac.hardware          631         296\n",
       "4                    sci.med          624         336\n",
       "9                  sci.space          623         330\n",
       "10   comp.os.ms-windows.misc          617         329\n",
       "15     talk.politics.mideast          609         309\n",
       "8         talk.politics.guns          581         305\n",
       "13               alt.atheism          508         271\n",
       "6         talk.politics.misc          503         252\n",
       "19        talk.religion.misc          414         191"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "# import text_normalize as tn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "data_df = pd.read_csv('clean_newsgroups.csv')\n",
    "# Split train and test sets\n",
    "train_corpus, test_corpus, train_label_nums, test_label_nums, train_label_names, test_label_names = train_test_split(np.array(data_df['Clean Article']),\n",
    "                                         np.array(data_df['Target Label']),\n",
    "                                         np.array(data_df['Target Name']),\n",
    "                                         test_size=0.33, random_state=42)\n",
    "print(train_corpus.shape, test_corpus.shape)\n",
    "\n",
    "# Distributions of articles\n",
    "\n",
    "from collections import Counter\n",
    "trd = dict(Counter(train_label_names))\n",
    "tsd = dict(Counter(test_label_names))\n",
    "\n",
    "print('The distribution of topics from the dataset is:')\n",
    "(pd.DataFrame([[key, trd[key], tsd[key]] for key in trd],\n",
    "             columns=['Target Label', 'Train Count', 'Test Count'])\n",
    ".sort_values(by=['Train Count', 'Test Count'],\n",
    "             ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering with Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (12264, 73402)  Test features shape: (6041, 73402)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build BOW features on train articles\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)\n",
    "# transform test articles into features\n",
    "cv_test_features = cv.transform(test_corpus)\n",
    "print('BOW model:> Train features shape:', cv_train_features.shape,\n",
    "      ' Test features shape:', cv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.6708655  0.65404965 0.67576375 0.66190282 0.67117117]\n",
      "Mean CV Accuracy: 0.6667505783960094\n",
      "Test Accuracy: 0.68200629034928\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(cv_train_features, train_label_names)\n",
    "mnb_bow_cv_scores = cross_val_score(mnb, cv_train_features, train_label_names, cv=5)\n",
    "mnb_bow_cv_mean_score = np.mean(mnb_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_bow_cv_mean_score)\n",
    "mnb_bow_test_score = mnb.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.68508736 0.67969068 0.71120163 0.6957942  0.69164619]\n",
      "Mean CV Accuracy: 0.692684013048077\n",
      "Test Accuracy: 0.7103128621089224\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "lr.fit(cv_train_features, train_label_names)\n",
    "lr_bow_cv_scores = cross_val_score(lr, cv_train_features, train_label_names, cv=5)\n",
    "lr_bow_cv_mean_score = np.mean(lr_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_bow_cv_mean_score)\n",
    "lr_bow_test_score = lr.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.63023161 0.62189662 0.65539715 0.6439363  0.63963964]\n",
      "Mean CV Accuracy: 0.6382202647817283\n",
      "Test Accuracy: 0.6580036417811621\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(cv_train_features, train_label_names)\n",
    "svm_bow_cv_scores = cross_val_score(svm, cv_train_features, train_label_names, cv=5)\n",
    "svm_bow_cv_mean_score = np.mean(svm_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_bow_cv_mean_score)\n",
    "svm_bow_test_score = svm.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.6363267  0.62962963 0.64928717 0.64271131 0.63554464]\n",
      "Mean CV Accuracy: 0.6386998882841927\n",
      "Test Accuracy: 0.6351597417646085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_sgd = SGDClassifier(loss='hinge', penalty=\"l2\", max_iter=5, random_state=42)\n",
    "svm_sgd.fit(cv_train_features, train_label_names)\n",
    "svmsgd_bow_cv_scores = cross_val_score(svm_sgd, cv_train_features, train_label_names, cv=5)\n",
    "svmsgd_bow_cv_mean_score = np.mean(svmsgd_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_bow_cv_mean_score)\n",
    "svmsgd_bow_test_score = svm_sgd.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.51889476 0.52340252 0.50753564 0.51000408 0.52129402]\n",
      "Mean CV Accuracy: 0.5162262055544148\n",
      "Test Accuracy: 0.5307068366164542\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(cv_train_features, train_label_names)\n",
    "rfc_bow_cv_scores = cross_val_score(rfc, cv_train_features, train_label_names, cv=5)\n",
    "rfc_bow_cv_mean_score = np.mean(rfc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_bow_cv_mean_score)\n",
    "rfc_bow_test_score = rfc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.5558716  0.55555556 0.54582485 0.55206207 0.54340704]\n",
      "Mean CV Accuracy: 0.5505442218548763\n",
      "Test Accuracy: 0.5505710975004139\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "gbc.fit(cv_train_features, train_label_names)\n",
    "gbc_bow_cv_scores = cross_val_score(gbc, cv_train_features, train_label_names, cv=5)\n",
    "gbc_bow_cv_mean_score = np.mean(gbc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_bow_cv_mean_score)\n",
    "gbc_bow_test_score = gbc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature learning with TF-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF model:> Train features shape: (12264, 73402)  Test features shape: (6041, 73402)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# build BOW features on train articles\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "# transform test articles into features\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape,\n",
    "      ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.70134092 0.69434269 0.7311609  0.70436913 0.71089271]\n",
      "Mean CV Accuracy: 0.7084212699897765\n",
      "Test Accuracy: 0.7204105280582686\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(tv_train_features, train_label_names)\n",
    "mnb_tfidf_cv_scores = cross_val_score(mnb, tv_train_features, train_label_names, cv=5)\n",
    "mnb_tfidf_cv_mean_score = np.mean(mnb_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_tfidf_cv_mean_score)\n",
    "mnb_tfidf_test_score = mnb.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.74075579 0.72649573 0.75315682 0.74846876 0.73669124]\n",
      "Mean CV Accuracy: 0.7411136678173997\n",
      "Test Accuracy: 0.7518622744578712\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "lr.fit(tv_train_features, train_label_names)\n",
    "lr_tfidf_cv_scores = cross_val_score(lr, tv_train_features, train_label_names, cv=5)\n",
    "lr_tfidf_cv_mean_score = np.mean(lr_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_tfidf_cv_mean_score)\n",
    "lr_tfidf_test_score = lr.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.74928891 0.74074074 0.77148676 0.76194365 0.75266175]\n",
      "Mean CV Accuracy: 0.7552243625062525\n",
      "Test Accuracy: 0.7659327925840093\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(tv_train_features, train_label_names)\n",
    "svm_tfidf_cv_scores = cross_val_score(svm, tv_train_features, train_label_names, cv=5)\n",
    "svm_tfidf_cv_mean_score = np.mean(svm_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_tfidf_cv_mean_score)\n",
    "svm_tfidf_test_score = svm.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.75700935 0.74277574 0.77230143 0.7639853  0.75184275]\n",
      "Mean CV Accuracy: 0.7575829132394601\n",
      "Test Accuracy: 0.7659327925840093\n"
     ]
    }
   ],
   "source": [
    "svm_sgd = SGDClassifier(loss='hinge', penalty=\"l2\", max_iter=5, random_state=42)\n",
    "svm_sgd.fit(tv_train_features, train_label_names)\n",
    "svmsgd_tfidf_cv_scores = cross_val_score(svm_sgd, tv_train_features, train_label_names, cv=5)\n",
    "svmsgd_tfidf_cv_mean_score = np.mean(svmsgd_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_tfidf_cv_mean_score)\n",
    "svmsgd_tfidf_test_score = svm_sgd.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.50873629 0.51933252 0.51446029 0.53736219 0.52538903]\n",
      "Mean CV Accuracy: 0.5210560609129864\n",
      "Test Accuracy: 0.5386525409700381\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(tv_train_features, train_label_names)\n",
    "rfc_tfidf_cv_scores = cross_val_score(rfc, tv_train_features, train_label_names, cv=5)\n",
    "rfc_tfidf_cv_mean_score = np.mean(rfc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_tfidf_cv_mean_score)\n",
    "rfc_tfidf_test_score = rfc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['soc.religion.christian', 'misc.forsale', 'soc.religion.christian',\n",
       "       ..., 'comp.os.ms-windows.misc', 'rec.autos',\n",
       "       'talk.politics.mideast'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict(tv_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.55343356 0.55555556 0.55885947 0.55410372 0.54217854]\n",
      "Mean CV Accuracy: 0.5528261695193868\n",
      "Test Accuracy: 0.5530541301109088\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "gbc.fit(tv_train_features, train_label_names)\n",
    "gbc_tfidf_cv_scores = cross_val_score(gbc, tv_train_features, train_label_names, cv=5)\n",
    "gbc_tfidf_cv_mean_score = np.mean(gbc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_tfidf_cv_mean_score)\n",
    "gbc_tfidf_test_score = gbc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Model</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Linear SVM (SGD)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Gradient Boosted Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CV Score (BOW)</td>\n",
       "      <td>0.666751</td>\n",
       "      <td>0.692684</td>\n",
       "      <td>0.63822</td>\n",
       "      <td>0.6387</td>\n",
       "      <td>0.516226</td>\n",
       "      <td>0.550544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Test Score (BOW)</td>\n",
       "      <td>0.682006</td>\n",
       "      <td>0.710313</td>\n",
       "      <td>0.658004</td>\n",
       "      <td>0.63516</td>\n",
       "      <td>0.530707</td>\n",
       "      <td>0.550571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CV Score (TF-IDF)</td>\n",
       "      <td>0.708421</td>\n",
       "      <td>0.741114</td>\n",
       "      <td>0.755224</td>\n",
       "      <td>0.757583</td>\n",
       "      <td>0.521056</td>\n",
       "      <td>0.552826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Test Score (TF-IDF)</td>\n",
       "      <td>0.720411</td>\n",
       "      <td>0.751862</td>\n",
       "      <td>0.765933</td>\n",
       "      <td>0.765933</td>\n",
       "      <td>0.538653</td>\n",
       "      <td>0.553054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                    1           2  \\\n",
       "Model                Naive Bayes  Logistic Regression  Linear SVM   \n",
       "CV Score (BOW)          0.666751             0.692684     0.63822   \n",
       "Test Score (BOW)        0.682006             0.710313    0.658004   \n",
       "CV Score (TF-IDF)       0.708421             0.741114    0.755224   \n",
       "Test Score (TF-IDF)     0.720411             0.751862    0.765933   \n",
       "\n",
       "                                    3              4  \\\n",
       "Model                Linear SVM (SGD)  Random Forest   \n",
       "CV Score (BOW)                 0.6387       0.516226   \n",
       "Test Score (BOW)              0.63516       0.530707   \n",
       "CV Score (TF-IDF)            0.757583       0.521056   \n",
       "Test Score (TF-IDF)          0.765933       0.538653   \n",
       "\n",
       "                                             5  \n",
       "Model                Gradient Boosted Machines  \n",
       "CV Score (BOW)                        0.550544  \n",
       "Test Score (BOW)                      0.550571  \n",
       "CV Score (TF-IDF)                     0.552826  \n",
       "Test Score (TF-IDF)                   0.553054  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['Naive Bayes', mnb_bow_cv_mean_score, mnb_bow_test_score,\n",
    "               mnb_tfidf_cv_mean_score, mnb_tfidf_test_score],\n",
    "              ['Logistic Regression', lr_bow_cv_mean_score, lr_bow_test_score, lr_tfidf_cv_mean_score, lr_tfidf_test_score],\n",
    "              ['Linear SVM', svm_bow_cv_mean_score, svm_bow_test_score,\n",
    "               svm_tfidf_cv_mean_score, svm_tfidf_test_score],\n",
    "              ['Linear SVM (SGD)', svmsgd_bow_cv_mean_score, svmsgd_bow_test_score, svmsgd_tfidf_cv_mean_score, svmsgd_tfidf_test_score],\n",
    "              ['Random Forest', rfc_bow_cv_mean_score, rfc_bow_test_score,\n",
    "               rfc_tfidf_cv_mean_score, rfc_tfidf_test_score],\n",
    "              ['Gradient Boosted Machines', gbc_bow_cv_mean_score, gbc_bow_test_score, gbc_tfidf_cv_mean_score, gbc_tfidf_test_score]],\n",
    "              columns=['Model', 'CV Score (BOW)', 'Test Score (BOW)',\n",
    "                      'CV Score (TF-IDF)', 'Test Score (TF-IDF)'],\n",
    "             ).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Multinomial Naïve Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_mnb__alpha', 'param_tfidf__ngram_range', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])\n",
      "Test Accuracy : 0.7790100976659493\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mnb_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('mnb', MultinomialNB())\n",
    "                       ])\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'mnb__alpha': [1e-5, 1e-4, 1e-2, 1e-1, 1]\n",
    "}\n",
    "\n",
    "gs_mnb = GridSearchCV(mnb_pipeline, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "gs_mnb = gs_mnb.fit(train_corpus, train_label_names)\n",
    "\n",
    "cv_results = gs_mnb.cv_results_\n",
    "try:\n",
    "    print(cv_results.keys())\n",
    "except:\n",
    "    None\n",
    "results_df = pd.DataFrame({'rank': cv_results['rank_test_score'],\n",
    "                           'params': cv_results['params'],\n",
    "                           'cv score (mean)': cv_results['mean_test_score'],\n",
    "                           'cv score (std)': cv_results['std_test_score']}\n",
    "              )\n",
    "results_df = results_df.sort_values(by=['rank'], ascending=True)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Test cv score on the test set\n",
    "best_mnb_test_score = gs_mnb.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_mnb_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('lr', LogisticRegression(penalty='l2', max_iter=100, random_state=42))\n",
    "                       ])\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'lr__C': [1, 5, 10]\n",
    "}\n",
    "gs_lr = GridSearchCV(lr_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_lr = gs_lr.fit(train_corpus, train_label_names)\n",
    "\n",
    "# evaluate best tuned model on the test dataset\n",
    "best_lr_test_score = gs_lr.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_lr_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the Linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.7801688462175137\n"
     ]
    }
   ],
   "source": [
    "# Tuning the Linear SVM model\n",
    "svm_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('svm', LinearSVC(random_state=42))\n",
    "                       ])\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'svm__C': [0.01, 0.1, 1, 5]\n",
    "}\n",
    "gs_svm = GridSearchCV(svm_pipeline, param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "gs_svm = gs_svm.fit(train_corpus, train_label_names)\n",
    "# evaluating best tuned model on the test dataset\n",
    "best_svm_test_score = gs_svm.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_svm_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from typing import List, TypeVar, Any\n",
    "from matplotlib.pyplot import figure\n",
    "Estimator = TypeVar('SklearnEstimator')\n",
    "class Evaluation:\n",
    "    def get_metrics(self,true_labels: List[str], predicted_labels: List[str]) -> str:\n",
    "        \"\"\"Take the true labels and predicted labels as input and \n",
    "        print out the performance metrics for the model\"\"\"\n",
    "        print('Accuracy:', np.round(\n",
    "            metrics.accuracy_score(true_labels,\n",
    "                                   predicted_labels),\n",
    "            4))\n",
    "        print('Precision:', np.round(\n",
    "            metrics.precision_score(true_labels,\n",
    "                                    predicted_labels,\n",
    "                                    average='weighted'),\n",
    "            4))\n",
    "        print('Recall:', np.round(\n",
    "            metrics.recall_score(true_labels,\n",
    "                                 predicted_labels,\n",
    "                                 average='weighted'),\n",
    "            4))\n",
    "        print('F1 Score:', np.round(\n",
    "            metrics.f1_score(true_labels,\n",
    "                             predicted_labels,\n",
    "                             average='weighted'),\n",
    "            4))\n",
    "    \n",
    "    def train_predict_model(self,classifier: Estimator ,\n",
    "                            train_features: List[List[float]], train_labels: List[str],\n",
    "                            test_features: List[List[float]]) -> List[str]:\n",
    "        \"\"\"Train the given model and output predictions based on input features\"\"\"\n",
    "        # build model\n",
    "        classifier.fit(train_features, train_labels)\n",
    "        # predict using model\n",
    "        predictions = classifier.predict(test_features)\n",
    "        return predictions\n",
    "    \n",
    "    def display_confusion_matrix(self,true_labels: List[str], predicted_labels: List[str], classes=[1, 0]) -> pd.DataFrame:\n",
    "        \"\"\"Build a confusion matrix using pandas dataframe from the given inputs and output it \"\"\"\n",
    "        total_classes = len(classes)\n",
    "        level_labels = [total_classes * [0], list(range(total_classes))]\n",
    "\n",
    "        cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels,\n",
    "                                      labels=classes)\n",
    "        cm_frame = pd.DataFrame(data=cm,\n",
    "                                columns=pd.MultiIndex(levels=[['Predicted:'], classes],\n",
    "                                                      labels=level_labels),\n",
    "                                index=pd.MultiIndex(levels=[['Actual:'], classes],\n",
    "                                                    labels=level_labels))\n",
    "        print(cm_frame)\n",
    "        \n",
    "    def display_classification_report(self,true_labels: List[str], predicted_labels: List[str], classes=[1, 0]) -> str:\n",
    "        \"\"\"Take true labels and predicted labels as inputs and output a string of classification report\"\"\"\n",
    "        report = metrics.classification_report(y_true=true_labels,\n",
    "                                               y_pred=predicted_labels,\n",
    "                                               labels=classes)\n",
    "        print(report)\n",
    "    def display_model_performance_metrics(self,true_labels: List[str], predicted_labels: List[str], classes=[1, 0]) -> Any:\n",
    "        print('Model Performance metrics:')\n",
    "        print('-' * 30)\n",
    "        get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
    "        print('\\nModel Classification report:')\n",
    "        print('-' * 30)\n",
    "        display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels,\n",
    "                                      classes=classes)\n",
    "        print('\\nPrediction Confusion Matrix:')\n",
    "        print('-' * 30)\n",
    "        display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels,\n",
    "                                 classes=classes)\n",
    "    def plot_model_decision_surface(self,clf: Estimator, train_features: List[List[float]], train_labels: List[str],\n",
    "                                plot_step=0.02, cmap=plt.cm.RdYlBu,\n",
    "                                markers=None, alphas=None, colors=None) -> figure:\n",
    "        if train_features.shape[1] != 2:\n",
    "            raise ValueError(\"X_train should have exactly 2 columnns!\")\n",
    "\n",
    "        x_min, x_max = train_features[:, 0].min() - plot_step, train_features[:, 0].max() + plot_step\n",
    "        y_min, y_max = train_features[:, 1].min() - plot_step, train_features[:, 1].max() + plot_step\n",
    "        # Create a grid using x, y values\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                             np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "        clf_est = clone(clf)\n",
    "        clf_est.fit(train_features, train_labels)\n",
    "        # Concatnate the results along the columns\n",
    "        if hasattr(clf_est, 'predict_proba'):\n",
    "            Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        else:\n",
    "            Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        cs = plt.contourf(xx, yy, Z, cmap=cmap)\n",
    "        \n",
    "        # Encode the labels from the training set\n",
    "        le = LabelEncoder()\n",
    "        y_enc = le.fit_transform(train_labels)\n",
    "        n_classes = len(le.classes_)\n",
    "        plot_colors = ''.join(colors) if colors else [None] * n_classes\n",
    "        label_names = le.classes_\n",
    "        markers = markers if markers else [None] * n_classes\n",
    "        alphas = alphas if alphas else [None] * n_classes\n",
    "        # Plot each label with colors, markers and alphas if specified\n",
    "        for i, color in zip(range(n_classes), plot_colors):\n",
    "            idx = np.where(y_enc == i)\n",
    "            plt.scatter(train_features[idx, 0], train_features[idx, 1], c=color,\n",
    "                        label=label_names[i], cmap=cmap, edgecolors='black',\n",
    "                        marker=markers[i], alpha=alphas[i])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def plot_model_roc_curve(self,clf, features: List[List[float]], true_labels: List[str], label_encoder=None, class_names=None) -> figure:\n",
    "        ## Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        if hasattr(clf, 'classes_'):\n",
    "            class_labels = clf.classes_\n",
    "        elif label_encoder:\n",
    "            class_labels = label_encoder.classes_\n",
    "        elif class_names:\n",
    "            class_labels = class_names\n",
    "        else:\n",
    "            raise ValueError('Unable to derive prediction classes, please specify class_names!')\n",
    "        n_classes = len(class_labels)\n",
    "        y_test = label_binarize(true_labels, classes=class_labels)\n",
    "        if n_classes == 2:\n",
    "            if hasattr(clf, 'predict_proba'):\n",
    "                prob = clf.predict_proba(features)\n",
    "                y_score = prob[:, prob.shape[1] - 1]\n",
    "            elif hasattr(clf, 'decision_function'):\n",
    "                prob = clf.decision_function(features)\n",
    "                y_score = prob[:, prob.shape[1] - 1]\n",
    "            else:\n",
    "                raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n",
    "                                     ''.format(roc_auc),\n",
    "                     linewidth=2.5)\n",
    "\n",
    "        elif n_classes > 2:\n",
    "            if hasattr(clf, 'predict_proba'):\n",
    "                y_score = clf.predict_proba(features)\n",
    "            elif hasattr(clf, 'decision_function'):\n",
    "                y_score = clf.decision_function(features)\n",
    "            else:\n",
    "                raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
    "\n",
    "            for i in range(n_classes):\n",
    "                fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "                roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "            ## Compute micro-average ROC curve and ROC area\n",
    "            fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "            roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "            ## Compute macro-average ROC curve and ROC area\n",
    "            # First aggregate all false positive rates\n",
    "            all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "            # Then interpolate all ROC curves at this points\n",
    "            mean_tpr = np.zeros_like(all_fpr)\n",
    "            for i in range(n_classes):\n",
    "                mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "            # Finally average it and compute AUC\n",
    "            mean_tpr /= n_classes\n",
    "            fpr[\"macro\"] = all_fpr\n",
    "            tpr[\"macro\"] = mean_tpr\n",
    "            roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "            ## Plot ROC curves\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                     label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                           ''.format(roc_auc[\"micro\"]), linewidth=3)\n",
    "\n",
    "            plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                     label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                           ''.format(roc_auc[\"macro\"]), linewidth=3)\n",
    "\n",
    "            for i, label in enumerate(class_labels):\n",
    "                plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                               ''.format(label, roc_auc[i]),\n",
    "                         linewidth=2, linestyle=':')\n",
    "        else:\n",
    "            raise ValueError('Number of classes should be atleast 2 or more')\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(clf: Estimator, test_labels: List[str], test_data: List[str], model: str) -> str:\n",
    "    \"\"\"Print out the performance of a model for 4 metrics\"\"\"\n",
    "    meu = Evaluation()\n",
    "    predictions = clf.predict(test_data)\n",
    "    unique_classes = list(set(test_labels))\n",
    "    print('4 summary metrics for {} are'.format(model))\n",
    "    meu.get_metrics(true_labels=test_labels, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "meu = Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 summary metrics for Multinomial Naive Bayes are\n",
      "Accuracy: 0.779\n",
      "Precision: 0.7807\n",
      "Recall: 0.779\n",
      "F1 Score: 0.776\n"
     ]
    }
   ],
   "source": [
    "mnb_predictions  = gs_mnb.predict(test_corpus)\n",
    "unique_classes = list(set(test_label_names))\n",
    "model = 'Multinomial Naive Bayes'\n",
    "print('4 summary metrics for {} are'.format(model))\n",
    "meu.get_metrics(true_labels=test_label_names, predicted_labels=mnb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "         sci.electronics       0.79      0.72      0.75       322\n",
      "         rec.motorcycles       0.83      0.81      0.82       316\n",
      "        rec.sport.hockey       0.91      0.91      0.91       288\n",
      "            misc.forsale       0.84      0.69      0.75       326\n",
      "  soc.religion.christian       0.67      0.90      0.77       310\n",
      "      talk.politics.misc       0.64      0.67      0.66       252\n",
      "      talk.religion.misc       0.61      0.31      0.42       191\n",
      "comp.sys.ibm.pc.hardware       0.68      0.77      0.72       329\n",
      "   comp.sys.mac.hardware       0.75      0.72      0.74       296\n",
      "                 sci.med       0.89      0.88      0.89       336\n",
      "      talk.politics.guns       0.72      0.79      0.75       305\n",
      "               sci.space       0.83      0.84      0.83       330\n",
      "           comp.graphics       0.66      0.78      0.71       295\n",
      "               rec.autos       0.80      0.83      0.82       293\n",
      "      rec.sport.baseball       0.92      0.90      0.91       315\n",
      "             alt.atheism       0.70      0.58      0.63       271\n",
      "          comp.windows.x       0.86      0.81      0.83       331\n",
      "   talk.politics.mideast       0.84      0.88      0.86       309\n",
      "               sci.crypt       0.80      0.87      0.83       297\n",
      " comp.os.ms-windows.misc       0.76      0.69      0.73       329\n",
      "\n",
      "                accuracy                           0.78      6041\n",
      "               macro avg       0.77      0.77      0.77      6041\n",
      "            weighted avg       0.78      0.78      0.78      6041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meu.display_classification_report(true_labels=test_label_names,\n",
    "                                  predicted_labels=mnb_predictions,\n",
    "                                  classes=unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 summary metrics for Support Vector Machines are\n",
      "Accuracy: 0.7802\n",
      "Precision: 0.7784\n",
      "Recall: 0.7802\n",
      "F1 Score: 0.7779\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = gs_svm.predict(test_corpus)\n",
    "unique_classes = list(set(test_label_names))\n",
    "model = 'Support Vector Machines'\n",
    "print('4 summary metrics for {} are'.format(model))\n",
    "meu.get_metrics(true_labels=test_label_names, predicted_labels=svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "         sci.electronics       0.74      0.75      0.74       322\n",
      "         rec.motorcycles       0.84      0.79      0.82       316\n",
      "        rec.sport.hockey       0.92      0.92      0.92       288\n",
      "            misc.forsale       0.78      0.81      0.80       326\n",
      "  soc.religion.christian       0.74      0.88      0.80       310\n",
      "      talk.politics.misc       0.67      0.67      0.67       252\n",
      "      talk.religion.misc       0.54      0.36      0.43       191\n",
      "comp.sys.ibm.pc.hardware       0.73      0.73      0.73       329\n",
      "   comp.sys.mac.hardware       0.76      0.75      0.75       296\n",
      "                 sci.med       0.81      0.88      0.84       336\n",
      "      talk.politics.guns       0.74      0.75      0.75       305\n",
      "               sci.space       0.86      0.78      0.82       330\n",
      "           comp.graphics       0.69      0.75      0.72       295\n",
      "               rec.autos       0.78      0.81      0.79       293\n",
      "      rec.sport.baseball       0.85      0.90      0.88       315\n",
      "             alt.atheism       0.71      0.63      0.67       271\n",
      "          comp.windows.x       0.83      0.81      0.82       331\n",
      "   talk.politics.mideast       0.87      0.87      0.87       309\n",
      "               sci.crypt       0.85      0.85      0.85       297\n",
      " comp.os.ms-windows.misc       0.74      0.72      0.73       329\n",
      "\n",
      "                accuracy                           0.78      6041\n",
      "               macro avg       0.77      0.77      0.77      6041\n",
      "            weighted avg       0.78      0.78      0.78      6041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# metrics performance for each topic\n",
    "meu.display_classification_report(true_labels=test_label_names,\n",
    "                                  predicted_labels=svm_predictions,\n",
    "                                  classes=unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(clf = gs_lr, test_labels = test_label_names, test_data = test_corpus, model = 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU 1.14",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "926px",
    "left": "0px",
    "right": "1593px",
    "top": "49px",
    "width": "327px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
