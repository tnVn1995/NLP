{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n",
      "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
      "syswgetrc = C:\\Program Files (x86)\\Gow/etc/wgetrc\n",
      "--2020-01-26 21:24:47--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
      "Resolving cs.nyu.edu... 128.122.49.30\n",
      "Connecting to cs.nyu.edu|128.122.49.30|:443... connected.\n",
      "Unable to establish SSL connection.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['idx', 'MATLAB_NOTES', 'nips00', 'nips01', 'nips02', 'nips03', 'nips04', 'nips05', 'nips06', 'nips07', 'nips08', 'nips09', 'nips10', 'nips11', 'nips12', 'orig', 'RAW_DATA_NOTES', 'README_yann']\n"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['nipstxt\\\\nips00',\n 'nipstxt\\\\nips01',\n 'nipstxt\\\\nips02',\n 'nipstxt\\\\nips03',\n 'nipstxt\\\\nips04',\n 'nipstxt\\\\nips05',\n 'nipstxt\\\\nips06',\n 'nipstxt\\\\nips07',\n 'nipstxt\\\\nips08',\n 'nipstxt\\\\nips09',\n 'nipstxt\\\\nips10',\n 'nipstxt\\\\nips11',\n 'nipstxt\\\\nips12']"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "p = Path(DATA_PATH)\n",
    "folders = list(p.glob('nips*'))\n",
    "[str(x) for x in folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1740"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
    "# Read all texts into a list.\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = list(folder.glob('*'))\n",
    "    for file_name in file_names:\n",
    "        with open(file_name, encoding='utf-8',\n",
    "                  errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 \nCONNECTIVITY VERSUS ENTROPY \nYaser S. Abu-Mostafa \nCalifornia Institute of Technology \nPasadena, CA 91125 \nABSTRACT \nHow does the connectivity of a neural network (number of synapses per \nneuron) relate to the complexity of the problems it can handle (measured by \nthe entropy)? Switching theory would suggest no relation at all, since all Boolean \nfunctions can be implemented using a circuit with very low connectivity (e.g., \nusing two-input NAND gates). However, for a network that learns a problem \nfrom examples using a local learning rule, we prove that the entropy of the \nproblem becomes a lower bound for the connectivity of the network. \nINTRODUCTION \nThe most distinguishing feature of neural networks is their ability to spon- \ntaneously learn the desired function from 'training' samples, i.e., their ability \nto program themselves. Clearly, a given neural network cannot just learn any \nfunction, there must be some restrictions on which networks can learn which \nfunctions. One obv\n"
    }
   ],
   "source": [
    "print(papers[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "zon', 'ha', 'shown', 'convex', 'piecewise', 'linear', 'make', 'possible', 'derive', 'exact', 'solution', 'discrete', 'pomdps', 'interested', 'pomdps', 'continuous', 'state', 'action', 'space', 'paying', 'tribute', 'fact', 'large', 'number', 'real-world', 'problem', 'continuous', 'nature', 'general', 'pomdps', 'solvable', 'exactly', 'little', 'known', 'special', 'case', 'solved', 'paper', 'proposes', 'approximate', 'approach', 'mc-pomdp', 'algorithm', 'accommodate', 'real-valued', 'space', 'model', 'central', 'idea', 'use', 'monte', 'carlo', 'sampling', 'belief', 'representation', 'propagation', 'reinforcement', 'learning', 'belief', 'space', 'employed', 'learn', 'value', 'function', 'using', 'sample-based', 'version', 'nearest', 'neighbor', 'generalization', 'empirical', 'result', 'illustrate', 'approach', 'find', 'close-to-optimal', 'solution', 'efficiently', 'monte', 'carlo', 'pomdps', '2.1', 'preliminary', 'pomdps', 'address', 'problem', 'selection', 'action', 'stationary', 'partially', 'observable', 'con-', 'trollable', 'markov', 'chain', 'establish', 'basic', 'vocabulary', 'let', 'define', 'state', 'point', 'time', 'world', 'specific', 'state', 'denoted', 'c.', 'monte', 'carlo', 'pomdps', 'action', 'agent', 'execute', 'action', 'denoted', 'a.', 'observation', 'sensor', 'agent', 'observe', 'noisy', 'projection', 'world', \"'s\", 'state', 'use', 'denote', 'observation', 'reward', 'additionally', 'agent', 'receives', 'rewards/penalties', 'denoted', 'simplify', 'notation', 'assume', 'reward', 'part', 'observation', 'specifically', 'use', 'denote', 'function', '``', 'extract', \"''\", 'reward', 'observation', 'throughout', 'paper', 'use', 'subscript', 'refer', 'specific', 'point', 'time', 'e.g.', 'st', 'refers', 'state', 'time', 'pomdps', 'characterized', 'three', 'probability', 'distribution', '1.', 'initial', 'distribution', '--', 'pr', 'zo', 'specifies', 'initial', 'distribution', 'state', 'time', '--', '2.', 'next', 'state', 'distribution', '/_t', 'z\\x7f', 'pt', 'oct', 'vc\\x7f', 'at_l', \"'-\", 'vct_l', '--', 'describes', 'likelihood', 'action', 'executed', 'state', 'lead', 'state', '3.', 'perceptual', 'distribution', 'pt', '\\x7fct', 'describes', 'likeli-', 'hood', 'observing', 'world', 'state', 'history', 'sequence', 'state', 'observation', 'simplicity', 'assume', 'action', 'observation', 'alternated', 'use', 'dt', 'denote', 'history', 'leading', 'time', 'dt', 'ot', 'at-l', 'ot-l', 'at-2', '...', 'ao', 'oo', 'fundamental', 'problem', 'pomdps', 'devise', 'policy', 'action', 'selection', 'maxi-', 'mizes', 'reward', 'policy', 'denoted', 'cr', 'mapping', 'history', 'action', 'assuming', 'action', 'chosen', 'policy', 'policy', 'induces', 'expected', 'cumulative', 'possibly', 'discounted', 'discount', 'factor', 'reward', 'defined', 'denotes', 'mathematical', 'expectation', 'pomdp', 'problem', 'thus', 'find', 'policy', 'or*', 'maximizes', \"''\", 'i.e.', 'or*', '--', 'argmax', \"''\", '2.2', 'belief', 'state', 'avoid', 'difficulty', 'learning', 'function', 'unbounded', 'input', 'history', 'arbitrarily', 'long', 'common', 'practice', 'map', 'history', 'belief', 'state', 'learn', 'mapping', 'belief', 'state', 'action', 'instead', 'formally', 'belief', 'state', 'denoted', 'probability', 'distribution', 'state', 'conditioned', 'past', 'action', 'observation', 'ot-', 'pr', 'xt', 'dt', 'pr', 'xt', 'ot', 'at_l', '...', 'oo', 'belief', 'computed', 'incrementally', 'using', 'knowledge', 'pomdp', \"'s\", 'defining', 'distribution', 'initially', '\\x7fr', 'obtain', 'ot+l', 'pr', 'xt+l', 'ot+l', '...', 'oo', 'o\\x7f', 'pr', 'ot+l', 'o\\x7f', 'pr', 'ot+l', 'o\\x7f', 'pr', 'ot+l', 'o0', '-r', 'xt+l', '...', 'o0', 'zt+\\x7f', 'pr', 'zt+l', '...', 'oo', 'zt', 'pr', 'zt', '...', 'oo', 'dzt', '\\x7fct+\\x7f', 'pr', 'oet+l', '\\x7fct', 'ot', 'dzt', 'thrun', '0.2', 'lllllllllnillllllllllllllllllllll', 'iiiilll', 'ii', 'ii', 'figure', 'sampling', 'likelihood-weighted', 'sampling', 'importance', 'sampling', 'bottom', 'graph', 'sample', 'shown', 'approximate', 'function', 'shown', 'top', 'height', 'sample', 'illustrates', 'importance', 'factor', 'denotes', 'constant', 'normalizer', 'derivation', 'follow', 'directly', 'fact', 'environment', 'stationary', 'markov', 'chain', 'future', 'state', 'observation', 'conditionally', 'independent', 'past', 'one', 'given', 'knowledge', 'state', 'equation', 'obtained', 'using', 'theorem', 'total', 'probability', 'armed', 'notion', 'belief', 'state', 'policy', 'mapping', 'belief', 'state', 'instead', 'history', 'action', \"o':0\", 'legitimacy', 'conditioning', 'instead', 'follows', 'directly', 'fact', 'environment', 'markov', 'implies', 'one', 'need', 'know', 'past', 'make', 'optimal', 'decision', '2.3', 'sample', 'representation', 'thus', 'far', 'intentionally', 'left', 'open', 'belief', 'state', 'represented', 'prior', 'work', 'state', 'space', 'discrete', 'discrete', 'world', 'belief', 'represented', 'collection', 'probability', 'one', 'state', 'hence', 'belief', 'represented', 'exactly', 'interested', 'real-valued', 'state', 'space', 'general', 'probability', 'distribution', 'real-', 'valued', 'space', 'posse', 'infinitely', 'many', 'dimension', 'hence', 'represented', 'digital', 'computer', 'key', 'idea', 'represent', 'belief', 'state', 'set', 'weighted', 'sample', 'drawn', 'belief', 'distribution', 'figure', 'illustrates', 'two', 'popular', 'scheme', 'sample-based', 'approxima-', 'tion', 'likelihood-weighted', 'sampling', 'sample', 'shown', 'bottom', 'figure', 'la', 'drawn', 'directly', 'target', 'distribution', 'labeled', 'figure', 'la', 'importance', 'sampling', 'sample', 'drawn', 'distribution', 'curve', 'labeled', 'figure', 'lb', 'latter', 'case', 'sample', 'annotated', 'numerical', 'importance', 'factor', 'account', 'difference', 'sampling', 'distribution', 'target', 'distribution', 'height', 'bar', 'figure', 'illustrates', 'importance', 'factor', 'importance', 'sampling', 'requires', '-\\x7f', 'case', 'throughout', 'paper', 'obviously', 'sampling', 'method', 'generate', 'approximation', 'mild', 'assumption', 'converge', 'denoting', 'sample', 'set', 'size', 'target', 'distribution', 'rate', 'context', 'pomdps', 'use', 'sample-based', 'representation', 'give', 'rise', 'following', 'algorithm', 'approximate', 'belief', 'propagation', 'c.f.', 'equation', 'algorithm', 'particle_filter', 'or+', 'ot+\\x7f', 'time', 'draw', 'random', 'state', 'zt', 'ot', 'monte', 'carlo', 'pomdps', 'sample', 'xt+', 'according', 'to\\x7f', 'xt+', 'xt', 'set', 'importance', 'factor', '--', 'ot', 'add', 'zt+', ',p', 'zt+', 'toot+', 'normalize', 'zt+', 'or+', '\\x7f-\\x7fp', 'zt+', 'return', 'ot', 'algorithm', 'converges', 'arbitrary', 'model', '/\\x7f', '\\x7fr', 'arbitrary', 'belief', 'distribution', 'defined', 'discrete', 'continuous', 'mixed', 'continuous-discrete', 'state', 'action', 'space', 'ha', 'minor', 'modification', 'proposed', 'name', 'like', 'particle', 'filter', 'condensation', 'algorithm', 'survival', 'fittest', 'context', 'robotics', 'monte', 'carlo', 'localization', '2.4', 'projection', 'conventional', 'planning', 'result', 'applying', 'action', 'state', 'zt', 'distribution', 'pr', 'zt+', 'rt+', 'zt', 'state', 'zt+', 'reward', 'rt+', 'next', 'time', 'step', 'operation', 'called', 'projection', 'pomdps', 'state', 'zt', 'unknown', 'instead', 'one', 'ha', 'compute', 'result', 'applying', 'action', 'belief', 'state', 'result', 'distribution', 'pt', 'or+', 'rt+', 'belief', 'state', 'or+', 'reward', 'rt+', 'since', 'belief', 'state', 'them-', 'self', 'distribution', 'result', 'projection', 'pomdps', 'technically', 'distribution', 'distribution', 'projection', 'algorithm', 'derived', 'follows', 'using', 'total', 'probability', 'obtain', 'pr', '0t+', ',/\\x7ft+', 'pr', 'ot+', ',rt+', 'dr', 'pr', 'ot+', ',t\\x7ft+', 'ot+', ',at', 'dt', 'pt', 'or+', 'dr', 'dot+', '**', 'term', 'ha', 'already', 'derived', 'previous', 'section', 'c.f.', 'equation', 'observation', 'reward/\\x7ft+', 'trivially', 'computed', 'observation', 'second', 'term', '**', 'obtained', 'integrating', 'unknown', 'variable', 'zt+', 'zt', 'exploiting', 'markov', 'property', 'pr', 'ot+t', 'dt', 'pr', 'ot+', 'xt+l', 'pr', 'xt+', 'dt', 'dzt+', 'pt', 'or+', 'zt+', 'pr', 'zt+', 'zt', 'pr', 'zt', 'idt', 'dzt', 'dzt+', 'i16', 'lead', 'following', 'approximate', 'algorithm', 'projecting', 'belief', 'state', 'spirit', 'paper', 'approach', 'us', 'monte', 'carlo', 'integration', 'instead', 'exact', 'integration', 'represents', 'distribution', 'distribution', 'distribution', 'sample', 'drawn', 'distribution', 'algorithm', 'partide_projecfion', '0t', 'ot', 'time', 'draw', 'random', 'state', 'zt', 'ot', 'sample', 'next', 'state', 'zt+', 'according', 'zt+', 'sample', 'observation', 'or+', 'according', 'ot+l', 'compute', 'ot', '=particle_filter', 'ot', 'add', 'ot+', ',\\x7f', 'ot+', 'toot', 'return', 'ot', 'result', 'algorithm', 'sample', 'set', 'belief', 'state', 'or+', 'reward', 'drawn', 'desired', 'distribution', 'pv', 'ot+l', 'rt+l', '-\\x7f', 'c\\x7f', 'ot', 'converges', 'probability', 'true', 'posterior', 's.', 'thrun', '2.5', 'learning', 'value', 'function', 'following', 'rich', 'literature', 'reinforcement', 'learning', 'approach', 'solves', 'pomdp', 'problem', 'value', 'iteration', 'belief', 'space', 'specifically', 'approach', 'recursively', 'learns', 'value', 'function', 'belief', 'state', 'action', 'backing', 'value', 'subsequent', 'belief', 'state', 'ot', '/l', 'ot_l_l', 'q-', '7maaxq', '0t+l', 'leaving', 'open', 'moment', 'represented', 'easy', 'seen', 'algorithm', 'particle_projection', 'applied', 'compute', 'monte', 'carlo', 'approximation', 'right', 'hand-side', 'expression', 'given', 'belief', 'state', 'ot', 'action', 'particle_projection', 'computes', 'sample', 'ot+l', 'or+l', 'expected', 'value', 'right', 'hand', 'side', 'approximated', 'ha', 'shown', 'side', 'equal', 'greedy', 'policy', 'argmaxq', 'optimal', 'i.e.', 'or*', '--', 'crq', 'furthermore', 'ha', 'shown', 'discrete', 'case', 'repetitive', 'application', 'lead', 'optimal', 'value', 'function', 'thus', 'optimal', 'policy', 'approach', 'essentially', 'performs', 'model-based', 'reinforcement', 'learning', 'belief', 'space', 'using', 'approximate', 'sample-based', 'representation', 'make', 'possible', 'apply', 'rich', 'bag', 'trick', 'found', 'literature', 'mdps', 'experiment', 'use', 'on-', 'line', 'reinforcement', 'learning', 'counter-based', 'exploration', 'experience', 'replay', 'determine', 'order', 'belief', 'state', 'updated', '2.6', 'nearest', 'neighbor', 'return', 'issue', 'represent', 'q.', 'since', 'operating', 'real-valued', 'space', 'sort', 'function', 'approximation', 'method', 'called', 'however', 'recall', 'accepts', 'probability', 'distribution', 'sample', 'set', 'input', 'make', 'existing', 'function', 'approximators', 'e.g.', 'neural', 'network', 'inapplicable', 'current', 'implementation', 'nearest', 'neighbor', 'applied', 'represent', 'q.', 'specifically', 'algorithm', 'maintains', 'set', 'sample', 'set', 'belief', 'state', 'annotated', 'action', 'q-value', 'new', 'belief', 'state', 'encountered', 'q-value', 'obtained', 'finding', 'nearest', 'neighbor', 'database', 'linearly', 'averaging', 'q-values', \"n't\", 'sufficiently', 'many', 'neighbor', 'within', 'pre-specified', 'maximum', 'distance', 'added', 'database', 'hence', 'database', 'grows', 'time', 'approach', 'us', 'kl', 'divergence', 'relative', 'entropy', 'distance', 'function', 'technically', 'kl-divergence', 'two', 'continuous', 'distribution', 'well-defined', 'applied', 'sample', 'set', 'however', 'computed', 'hence', 'evaluating', 'distance', 'be-', 'tween', 'two', 'different', 'sample', 'set', 'approach', 'map', 'continuous-valued', 'density', 'using', 'gaussian', 'kernel', 'us', 'monte', 'carlo', 'sampling', 'approximate', 'kl', 'divergence', 'algorithm', 'fairly', 'generic', 'extension', 'nearest', 'neighbor', 'func-', 'tion', 'approximation', 'density', 'space', 'density', 'represented', 'sample', 'space', 'limitation', 'preclude', 'providing', 'detail', 'see', 'experimental', 'result', 'preliminary', 'result', 'obtained', 'world', 'shown', 'two', 'domain', 'one', 'synthetic', 'one', 'using', 'simulator', 'rwi', 'b21', 'robot', 'synthetic', 'environment', 'figure', '2a', 'agent', 'start', 'lower', 'left', 'corner', 'objective', 'reach', '``', 'heaven', \"''\", 'either', 'upper', 'left', 'corner', 'lower', 'right', '\\x7fstdctly', 'speaking', 'kl', 'divergence', 'distance', 'metric', 'ignored', 'monte', 'carlo', 'pomdps', 'figure', 'environment', 'schematically', 'average', 'performance', 'reward', 'function', 'training', 'episode', 'black', 'graph', 'corresponds', 'smaller', 'environment', 'step', 'min', 'grey', 'graph', 'larger', 'environment', 'step', 'min', 'result', 'plotted', 'function', 'number', 'backup', 'thousand', 'comer', 'opposite', 'location', '``', 'hell', \"''\", 'agent', 'doe', 'know', 'location', 'heaven', 'ask', '``', 'priest', \"''\", 'located', 'upper', 'right', 'comer', 'thus', 'optimal', 'solution', 'requires', 'agent', 'go', 'first', 'priest', 'head', 'heaven', 'state', 'space', 'contains', 'real-valued', 'coordinate', 'agent', 'discrete', 'location', 'heaven', 'component', 'unobservable', 'addition', 'knowing', 'location', 'heaven', 'agent', 'also', 'sense', 'real-valued', 'coordinate', 'random', 'motion', 'noise', 'injected', 'move', 'agent', 'hit', 'boundary', 'penalized', 'also', 'told', 'boundary', 'hit', 'make', 'possible', 'infer', 'coordinate', 'along', 'one', 'axis', 'however', 'notice', 'initial', 'coordinate', 'agent', 'known', 'optimal', 'solution', 'take', 'approximately', 'step', 'thus', 'successful', 'pomdp', 'planner', 'must', 'capable', 'looking', 'step', 'ahead', 'use', 'term', '``', 'successful', 'policy', \"''\", 'refer', 'policy', 'always', 'lead', 'heaven', 'even', 'path', 'suboptimal', 'policy', 'successful', 'agent', 'must', 'learned', 'first', 'move', 'priest', 'information', 'gathering', 'proceed', 'right', 'target', 'location', 'figure', '2b', 'show', 'performance', 'result', 'averaged', 'experiment', 'solid', 'black', 'curve', 'diagram', 'plot', 'average', 'cumulative', 'reward', 'function', 'number', 'training', 'episode', 'figure', '2b', 'function', 'number', 'backup', 'figure', '2c', 'successful', 'policy', 'wa', 'consistently', 'found', 'episode', '6,150', 'backup', 'experiment', 'current', 'implementation', '6,150', 'backup', 'require', 'approximately', 'minute', 'pentium', 'pc', 'experiment', 'successful', 'policy', 'wa', 'identified', 'episode', 'le', '1,500', 'backup', 'minute', 'successful', 'policy', 'found', 'learning', 'gradually', 'optimizes', 'path', 'investigate', 'scaling', 'doubled', 'size', 'environment', 'quadrupling', 'size', 'state', 'space', 'making', 'optimal', 'solution', 'step', 'long', 'result', 'depicted', 'gray', 'curve', 'figure', '2b', 'successful', 'policy', 'consistently', 'found', 'episode', '10,250', 'backup', 'minute', 'run', 'successful', 'policy', 'identified', 'episode', 'also', 'applied', 'mc-pomdps', 'robotic', 'locate-and-retrieve', 'task', 'robot', 'figure', '3a', 'find', 'grasp', 'object', 'somewhere', 'vicinity', 'floor', 'table', 'height', 'robot', \"'s\", 'task', 'grasp', 'object', 'using', 'gripper', 'rewarded', 'successfully', 'grasping', 'object', 'penalized', 'unsuccessful', 'grasp', 'moving', 'far', 'away', 'object', 'state', 'space', 'continuous', 'coordinate', 'discrete', 'object', \"'s\", 'height', 'robot', 'us', 'mono-camera', 'system', 'object', 'detection', 'hence', 'viewing', 'object', 'single', 'location', 'insufficient', '3d', 'localization', 'moreover', 'initially', 'object', 'might', 'sight', 'robot', \"'s\", 'camera', 'robot', 'must', 'look', 'around', 'first', 'simulation', 'assume', 'general', 'detection', 'error', 'false-positive', 'false-negative', 'additional', 'gaussian', 'noise', 'object', 'detected', 'correctly', 'robot', \"'s\", 'action', 'include', 'tum', 'variable', 'angle', 'translation', 'variable', 'distance', 'grasp', 'one', 'two', 'legal', 'height', 'robot', 'control', 'erroneous', 'variance', 'c-y-space', 'rotational', 'space', 'typical', 'belief', 'state', 'range', 'uniformly', 'distributed', 'sample', 'set', 'initial', 'belief', 'sample', 'narrowly', 'focused', 'specific', '-\\x7ft-z', 'location', 's.', 'thrun', 'figure', 'find', 'fetch', 'task', 'success', 'iteration', 'mobile', 'robot', 'gripper', 'camera', 'holding', 'target', 'object', 'experiment', 'carded', 'simulation', 'three', 'successful', 'run', 'trajectory', 'projected', '2d', 'success', 'rate', 'function', 'number', 'planning', 'step', 'figure', '3c', 'show', 'rate', 'successful', 'grasp', 'function', 'iteration', 'action', 'initially', 'robot', 'fails', 'grasp', 'object', 'approximately', '4,000', 'iteration', 'perfor-', 'mance', 'surpasses', 'planning', 'time', 'order', 'hour', 'however', 'robot', 'fails', 'reach', 'part', 'certain', 'initial', 'configuration', 'make', 'impossible', 'succeed', 'e.g.', 'object', 'close', 'maximum', 'allowed', 'distance', 'part', 'robot', 'occasionally', 'miss', 'object', 'centimeter', 'figure', '3b', 'depicts', 'three', 'successful', 'example', 'trajectory', 'three', 'robot', 'initially', 'search', 'object', 'move', 'towards', 'grasp', 'successfully', 'discussion', 'presented', 'monte', 'carlo', 'approach', 'learning', 'act', 'partially', 'observable', 'markov', 'decision', 'process', 'pomdps', 'approach', 'represents', 'belief', 'distribution', 'using', 'sample', 'drawn', 'distribution', 'reinforcement', 'learning', 'belief', 'space', 'applied', 'learn', 'optimal', 'policy', 'using', 'sample-based', 'version', 'nearest', 'neighbor', 'generalization', 'backup', 'performed', 'using', 'monte', 'carlo', 'sampling', 'initial', 'experimental', 'result', 'demonstrate', 'approach', 'applicable', 'real-valued', 'domain', 'yield', 'good', 'performance', 'result', 'environment', '--', 'pomdp', 'standard', '--', 'relatively', 'large', 'reference', 'aaai', 'fall', 'symposium', 'pomdps', '1998.', 'see', 'http', '//www.cs.duke.edu/\\x7fmlittman/talks/', 'pomdp-symposium', 'html', 'r.e', 'bellman', 'dynamic', 'programming', 'princeton', 'university', 'press', 'p.', 'dayan', 't.', 'j.', 'sejnowski', 'td', 'converges', 'probability', 'd.', 'fox', 'w.', 'burgard', 'dellaert', 's.', 'thrun', 'monte', 'carlo', 'localization', 'efficient', 'position', 'estimation', 'mobile', 'robot', 'aaai-99', 'm.', 'isard', 'a.', 'b\\x7fake', 'c\\x7fndensati\\x7fn', 'c\\x7fnditi\\x7fna\\x7f', 'density', 'pr\\x7fpagati\\x7fnf\\x7fr', 'visua\\x7f', 'tracking', '\\x7fnternati\\x7fnalj\\x7furnal', '\\x7ff', 'c\\x7frnputer', 'vision', 'l.p.', 'kaelbling', 'm.l', 'littman', 'a.r', 'cassandra', 'planning', 'acting', 'partially', 'observable', 'stochastic', 'domain', 'submitted', 'publication', 'l.p.', 'kaelbling', 'm.l', 'littman', 'a.w', 'moore', 'reinforcement', 'learning', 'survey', 'jair', 'k.', 'kanazawa', 'd.', 'koller', 's.j', 'russell', 'stochastic', 'simulation', 'algorithm', 'dynamic', 'probabilistic', 'network', 'uai-95', 'l.-j', 'lin', 'self-improving', 'reactive', 'agent', 'based', 'reinforcement', 'learning', 'planning', 'teaching', 'machine', 'learning', 'm.l', 'littman', 'a.r', 'cassandra', 'l.p.', 'kaelbling', 'learning', 'policy', 'partially', 'observable', 'environment', 'scaling', 'icml-95', 'a.w', 'moore', 'c.g', 'atkeson', 's.a.', 'schaal', 'locally', 'weighted', 'learning', 'control', 'aireview', 'd.', 'ormoneit', 's.', 'sen.', 'kernel-based', 'reinforcementlearning', 'tr', '1999-8', 'statistic', 'stanford', 'university', 'm.', 'pitt', 'n.', 'shephard', 'filtering', 'via', 'simulation', 'auxiliary', 'particle', 'filter', 'journal', 'american', 'statistical', 'association', 'e.', 'sondik', 'optimal', 'control', 'partially', 'observable', 'markov', 'process', 'phd', 'thesis', 'stanford', 'r.s', 'sutton', 'a.g.', 'barto', 'reinforcement', 'learning', 'introduction', 'mit', 'press', 'm.a', 'tanner', 'tool', 'statistical', 'inference', 'springer', 'verlag', 'c.j.c.h', 'watkins', 'learning', 'delayed', 'reward', 'phd', 'thesis', 'king', \"'s\", 'college', 'cambridge']]\n"
    }
   ],
   "source": [
    "import nltk\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "# wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "# wtk = nltk.word_tokenize()\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in nltk.word_tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "    return norm_papers\n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))\n",
    "print(norm_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " 'state', 'finally', 'sample', 'based', 'version', 'nearest', 'neighbor', 'used', 'generalize', 'across', 'state', 'initial', 'empirical', 'result', 'suggest', 'approach', 'work', 'well', 'practical', 'application', 'introduction', 'pomdps', 'address', 'problem', 'acting', 'optimally', 'partially', 'observable', 'dynamic', 'environ', 'ment', 'pomdps', 'learner', 'interacts', 'stochastic', 'environment', 'whose', 'state', 'partially', 'observable', 'action', 'change', 'state', 'environment', 'lead', 'numerical', 'penalty', 'reward', 'may', 'observed', 'unknown', 'temporal', 'delay', 'learner', 'goal', 'devise', 'policy', 'action', 'selection', 'maximizes', 'reward', 'obviously', 'pomdp', 'framework', 'embrace', 'large', 'range', 'practical', 'problem', 'past', 'work', 'ha', 'predominately', 'studied', 'pomdps', 'discrete', 'world', 'discrete', 'world', 'advantage', 'distribution', 'state', 'called', 'belief', 'state', 'represented', 'exactly', 'using', 'one', 'parameter', 'per', 'state', 'optimal', 'value', 'function', 'finite', 'planning', 'horizon', 'ha', 'shown', 'convex', 'piecewise', 'linear', 'make', 'possible', 'derive', 'exact', 'solution', 'discrete', 'pomdps', 'interested', 'pomdps', 'continuous', 'state', 'action', 'space', 'paying', 'tribute', 'fact', 'large', 'number', 'real', 'world', 'problem', 'continuous', 'nature', 'general', 'pomdps', 'solvable', 'exactly', 'little', 'known', 'special', 'case', 'solved', 'paper', 'proposes', 'approximate', 'approach', 'mc', 'pomdp', 'algorithm', 'accommodate', 'real', 'valued', 'space', 'model', 'central', 'idea', 'use', 'monte', 'carlo', 'sampling', 'belief', 'representation', 'propagation', 'reinforcement', 'learning', 'belief', 'space', 'employed', 'learn', 'value', 'function', 'using', 'sample', 'based', 'version', 'nearest', 'neighbor', 'generalization', 'empirical', 'result', 'illustrate', 'approach', 'find', 'close', 'optimal', 'solution', 'efficiently', 'monte', 'carlo', 'pomdps', 'preliminary', 'pomdps', 'address', 'problem', 'selection', 'action', 'stationary', 'partially', 'observable', 'con', 'trollable', 'markov', 'chain', 'establish', 'basic', 'vocabulary', 'let', 'define', 'state', 'point', 'time', 'world', 'specific', 'state', 'denoted', 'monte', 'carlo', 'pomdps', 'action', 'agent', 'execute', 'action', 'denoted', 'observation', 'sensor', 'agent', 'observe', 'noisy', 'projection', 'world', 'state', 'use', 'denote', 'observation', 'reward', 'additionally', 'agent', 'receives', 'reward', 'penalty', 'denoted', 'simplify', 'notation', 'assume', 'reward', 'part', 'observation', 'specifically', 'use', 'denote', 'function', 'extract', 'reward', 'observation', 'throughout', 'paper', 'use', 'subscript', 'refer', 'specific', 'point', 'time', 'st', 'refers', 'state', 'time', 'pomdps', 'characterized', 'three', 'probability', 'distribution', 'initial', 'distribution', 'pr', 'zo', 'specifies', 'initial', 'distribution', 'state', 'time', 'next', 'state', 'distribution', '_t', 'pt', 'oct', 'vc', 'at_l', 'vct_l', 'describes', 'likelihood', 'action', 'executed', 'state', 'lead', 'state', 'perceptual', 'distribution', 'pt', 'ct', 'describes', 'likeli', 'hood', 'observing', 'world', 'state', 'history', 'sequence', 'state', 'observation', 'simplicity', 'assume', 'action', 'observation', 'alternated', 'use', 'dt', 'denote', 'history', 'leading', 'time', 'dt', 'ot', 'ot', 'ao', 'oo', 'fundamental', 'problem', 'pomdps', 'devise', 'policy', 'action', 'selection', 'maxi', 'mizes', 'reward', 'policy', 'denoted', 'cr', 'mapping', 'history', 'action', 'assuming', 'action', 'chosen', 'policy', 'policy', 'induces', 'expected', 'cumulative', 'possibly', 'discounted', 'discount', 'factor', 'reward', 'defined', 'denotes', 'mathematical', 'expectation', 'pomdp', 'problem', 'thus', 'find', 'policy', 'maximizes', 'argmax', 'belief', 'state', 'avoid', 'difficulty', 'learning', 'function', 'unbounded', 'input', 'history', 'arbitrarily', 'long', 'common', 'practice', 'map', 'history', 'belief', 'state', 'learn', 'mapping', 'belief', 'state', 'action', 'instead', 'formally', 'belief', 'state', 'denoted', 'probability', 'distribution', 'state', 'conditioned', 'past', 'action', 'observation', 'ot', 'pr', 'xt', 'dt', 'pr', 'xt', 'ot', 'at_l', 'oo', 'belief', 'computed', 'incrementally', 'using', 'knowledge', 'pomdp', 'defining', 'distribution', 'initially', 'obtain', 'ot', 'pr', 'xt', 'ot', 'oo', 'pr', 'ot', 'pr', 'ot', 'pr', 'ot', 'o0', 'xt', 'o0', 'zt', 'pr', 'zt', 'oo', 'zt', 'pr', 'zt', 'oo', 'dzt', 'ct', 'pr', 'oet', 'ct', 'ot', 'dzt', 'thrun', 'lllllllllnillllllllllllllllllllll', 'iiiilll', 'ii', 'ii', 'figure', 'sampling', 'likelihood', 'weighted', 'sampling', 'importance', 'sampling', 'bottom', 'graph', 'sample', 'shown', 'approximate', 'function', 'shown', 'top', 'height', 'sample', 'illustrates', 'importance', 'factor', 'denotes', 'constant', 'normalizer', 'derivation', 'follow', 'directly', 'fact', 'environment', 'stationary', 'markov', 'chain', 'future', 'state', 'observation', 'conditionally', 'independent', 'past', 'one', 'given', 'knowledge', 'state', 'equation', 'obtained', 'using', 'theorem', 'total', 'probability', 'armed', 'notion', 'belief', 'state', 'policy', 'mapping', 'belief', 'state', 'instead', 'history', 'action', 'legitimacy', 'conditioning', 'instead', 'follows', 'directly', 'fact', 'environment', 'markov', 'implies', 'one', 'need', 'know', 'past', 'make', 'optimal', 'decision', 'sample', 'representation', 'thus', 'far', 'intentionally', 'left', 'open', 'belief', 'state', 'represented', 'prior', 'work', 'state', 'space', 'discrete', 'discrete', 'world', 'belief', 'represented', 'collection', 'probability', 'one', 'state', 'hence', 'belief', 'represented', 'exactly', 'interested', 'real', 'valued', 'state', 'space', 'general', 'probability', 'distribution', 'real', 'valued', 'space', 'posse', 'infinitely', 'many', 'dimension', 'hence', 'cannot', 'represented', 'digital', 'computer', 'key', 'idea', 'represent', 'belief', 'state', 'set', 'weighted', 'sample', 'drawn', 'belief', 'distribution', 'figure', 'illustrates', 'two', 'popular', 'scheme', 'sample', 'based', 'approxima', 'tion', 'likelihood', 'weighted', 'sampling', 'sample', 'shown', 'bottom', 'figure', 'la', 'drawn', 'directly', 'target', 'distribution', 'labeled', 'figure', 'la', 'importance', 'sampling', 'sample', 'drawn', 'distribution', 'curve', 'labeled', 'figure', 'lb', 'latter', 'case', 'sample', 'annotated', 'numerical', 'importance', 'factor', 'account', 'difference', 'sampling', 'distribution', 'target', 'distribution', 'height', 'bar', 'figure', 'illustrates', 'importance', 'factor', 'importance', 'sampling', 'requires', 'case', 'throughout', 'paper', 'obviously', 'sampling', 'method', 'generate', 'approximation', 'mild', 'assumption', 'converge', 'denoting', 'sample', 'set', 'size', 'target', 'distribution', 'rate', 'context', 'pomdps', 'use', 'sample', 'based', 'representation', 'give', 'rise', 'following', 'algorithm', 'approximate', 'belief', 'propagation', 'equation', 'algorithm', 'particle_filter', 'ot', 'time', 'draw', 'random', 'state', 'zt', 'ot', 'monte', 'carlo', 'pomdps', 'sample', 'xt', 'according', 'xt', 'xt', 'set', 'importance', 'factor', 'ot', 'add', 'zt', 'zt', 'toot', 'normalize', 'zt', 'zt', 'return', 'ot', 'algorithm', 'converges', 'arbitrary', 'model', 'arbitrary', 'belief', 'distribution', 'defined', 'discrete', 'continuous', 'mixed', 'continuous', 'discrete', 'state', 'action', 'space', 'ha', 'minor', 'modification', 'proposed', 'name', 'like', 'particle', 'filter', 'condensation', 'algorithm', 'survival', 'fittest', 'context', 'robotics', 'monte', 'carlo', 'localization', 'projection', 'conventional', 'planning', 'result', 'applying', 'action', 'state', 'zt', 'distribution', 'pr', 'zt', 'rt', 'zt', 'state', 'zt', 'reward', 'rt', 'next', 'time', 'step', 'operation', 'called', 'projection', 'pomdps', 'state', 'zt', 'unknown', 'instead', 'one', 'ha', 'compute', 'result', 'applying', 'action', 'belief', 'state', 'result', 'distribution', 'pt', 'rt', 'belief', 'state', 'reward', 'rt', 'since', 'belief', 'state', 'self', 'distribution', 'result', 'projection', 'pomdps', 'technically', 'distribution', 'distribution', 'projection', 'algorithm', 'derived', 'follows', 'using', 'total', 'probability', 'obtain', 'pr', '0t', 'pr', 'ot', 'rt', 'dr', 'pr', 'ot', 'ot', 'dt', 'pt', 'dr', 'dot', 'term', 'ha', 'already', 'derived', 'previous', 'section', 'equation', 'observation', 'reward', 'trivially', 'computed', 'observation', 'second', 'term', 'obtained', 'integrating', 'unknown', 'variable', 'zt', 'zt', 'exploiting', 'markov', 'property', 'pr', 'ot', 'dt', 'pr', 'ot', 'xt', 'pr', 'xt', 'dt', 'dzt', 'pt', 'zt', 'pr', 'zt', 'zt', 'pr', 'zt', 'idt', 'dzt', 'dzt', 'i16', 'lead', 'following', 'approximate', 'algorithm', 'projecting', 'belief', 'state', 'spirit', 'paper', 'approach', 'us', 'monte', 'carlo', 'integration', 'instead', 'exact', 'integration', 'represents', 'distribution', 'distribution', 'distribution', 'sample', 'drawn', 'distribution', 'algorithm', 'partide_projecfion', '0t', 'ot', 'time', 'draw', 'random', 'state', 'zt', 'ot', 'sample', 'next', 'state', 'zt', 'according', 'zt', 'sample', 'observation', 'according', 'ot', 'compute', 'ot', 'particle_filter', 'ot', 'add', 'ot', 'ot', 'toot', 'return', 'ot', 'result', 'algorithm', 'sample', 'set', 'belief', 'state', 'reward', 'drawn', 'desired', 'distribution', 'pv', 'ot', 'rt', 'ot', 'converges', 'probability', 'true', 'posterior', 'thrun', 'learning', 'value', 'function', 'following', 'rich', 'literature', 'reinforcement', 'learning', 'approach', 'solves', 'pomdp', 'problem', 'value', 'iteration', 'belief', 'space', 'specifically', 'approach', 'recursively', 'learns', 'value', 'function', 'belief', 'state', 'action', 'backing', 'value', 'subsequent', 'belief', 'state', 'ot', 'ot_l_l', '7maaxq', '0t', 'leaving', 'open', 'moment', 'represented', 'easy', 'seen', 'algorithm', 'particle_projection', 'applied', 'compute', 'monte', 'carlo', 'approximation', 'right', 'hand', 'side', 'expression', 'given', 'belief', 'state', 'ot', 'action', 'particle_projection', 'computes', 'sample', 'ot', 'expected', 'value', 'right', 'hand', 'side', 'approximated', 'ha', 'shown', 'side', 'equal', 'greedy', 'policy', 'argmaxq', 'optimal', 'crq', 'furthermore', 'ha', 'shown', 'discrete', 'case', 'repetitive', 'application', 'lead', 'optimal', 'value', 'function', 'thus', 'optimal', 'policy', 'approach', 'essentially', 'performs', 'model', 'based', 'reinforcement', 'learning', 'belief', 'space', 'using', 'approximate', 'sample', 'based', 'representation', 'make', 'possible', 'apply', 'rich', 'bag', 'trick', 'found', 'literature', 'mdps', 'experiment', 'use', 'line', 'reinforcement', 'learning', 'counter', 'based', 'exploration', 'experience', 'replay', 'determine', 'order', 'belief', 'state', 'updated', 'nearest', 'neighbor', 'return', 'issue', 'represent', 'since', 'operating', 'real', 'valued', 'space', 'sort', 'function', 'approximation', 'method', 'called', 'however', 'recall', 'accepts', 'probability', 'distribution', 'sample', 'set', 'input', 'make', 'existing', 'function', 'approximators', 'neural', 'network', 'inapplicable', 'current', 'implementation', 'nearest', 'neighbor', 'applied', 'represent', 'specifically', 'algorithm', 'maintains', 'set', 'sample', 'set', 'belief', 'state', 'annotated', 'action', 'value', 'new', 'belief', 'state', 'encountered', 'value', 'obtained', 'finding', 'nearest', 'neighbor', 'database', 'linearly', 'averaging', 'value', 'sufficiently', 'many', 'neighbor', 'within', 'pre', 'specified', 'maximum', 'distance', 'added', 'database', 'hence', 'database', 'grows', 'time', 'approach', 'us', 'kl', 'divergence', 'relative', 'entropy', 'distance', 'function', 'technically', 'kl', 'divergence', 'two', 'continuous', 'distribution', 'well', 'defined', 'applied', 'sample', 'set', 'however', 'cannot', 'computed', 'hence', 'evaluating', 'distance', 'tween', 'two', 'different', 'sample', 'set', 'approach', 'map', 'continuous', 'valued', 'density', 'using', 'gaussian', 'kernel', 'us', 'monte', 'carlo', 'sampling', 'approximate', 'kl', 'divergence', 'algorithm', 'fairly', 'generic', 'extension', 'nearest', 'neighbor', 'func', 'tion', 'approximation', 'density', 'space', 'density', 'represented', 'sample', 'space', 'limitation', 'preclude', 'providing', 'detail', 'see', 'experimental', 'result', 'preliminary', 'result', 'obtained', 'world', 'shown', 'two', 'domain', 'one', 'synthetic', 'one', 'using', 'simulator', 'rwi', 'b21', 'robot', 'synthetic', 'environment', 'figure', '2a', 'agent', 'start', 'lower', 'left', 'corner', 'objective', 'reach', 'heaven', 'either', 'upper', 'left', 'corner', 'lower', 'right', 'stdctly', 'speaking', 'kl', 'divergence', 'distance', 'metric', 'ignored', 'monte', 'carlo', 'pomdps', 'figure', 'environment', 'schematically', 'average', 'performance', 'reward', 'function', 'training', 'episode', 'black', 'graph', 'corresponds', 'smaller', 'environment', 'step', 'min', 'grey', 'graph', 'larger', 'environment', 'step', 'min', 'result', 'plotted', 'function', 'number', 'backup', 'thousand', 'comer', 'opposite', 'location', 'hell', 'agent', 'doe', 'know', 'location', 'heaven', 'ask', 'priest', 'located', 'upper', 'right', 'comer', 'thus', 'optimal', 'solution', 'requires', 'agent', 'go', 'first', 'priest', 'head', 'heaven', 'state', 'space', 'contains', 'real', 'valued', 'coordinate', 'agent', 'discrete', 'location', 'heaven', 'component', 'unobservable', 'addition', 'knowing', 'location', 'heaven', 'agent', 'also', 'cannot', 'sense', 'real', 'valued', 'coordinate', 'random', 'motion', 'noise', 'injected', 'move', 'agent', 'hit', 'boundary', 'penalized', 'also', 'told', 'boundary', 'hit', 'make', 'possible', 'infer', 'coordinate', 'along', 'one', 'axis', 'however', 'notice', 'initial', 'coordinate', 'agent', 'known', 'optimal', 'solution', 'take', 'approximately', 'step', 'thus', 'successful', 'pomdp', 'planner', 'must', 'capable', 'looking', 'step', 'ahead', 'use', 'term', 'successful', 'policy', 'refer', 'policy', 'always', 'lead', 'heaven', 'even', 'path', 'suboptimal', 'policy', 'successful', 'agent', 'must', 'learned', 'first', 'move', 'priest', 'information', 'gathering', 'proceed', 'right', 'target', 'location', 'figure', '2b', 'show', 'performance', 'result', 'averaged', 'experiment', 'solid', 'black', 'curve', 'diagram', 'plot', 'average', 'cumulative', 'reward', 'function', 'number', 'training', 'episode', 'figure', '2b', 'function', 'number', 'backup', 'figure', '2c', 'successful', 'policy', 'wa', 'consistently', 'found', 'episode', 'backup', 'experiment', 'current', 'implementation', 'backup', 'require', 'approximately', 'minute', 'pentium', 'pc', 'experiment', 'successful', 'policy', 'wa', 'identified', 'episode', 'le', 'backup', 'minute', 'successful', 'policy', 'found', 'learning', 'gradually', 'optimizes', 'path', 'investigate', 'scaling', 'doubled', 'size', 'environment', 'quadrupling', 'size', 'state', 'space', 'making', 'optimal', 'solution', 'step', 'long', 'result', 'depicted', 'gray', 'curve', 'figure', '2b', 'successful', 'policy', 'consistently', 'found', 'episode', 'backup', 'minute', 'run', 'successful', 'policy', 'identified', 'episode', 'also', 'applied', 'mc', 'pomdps', 'robotic', 'locate', 'retrieve', 'task', 'robot', 'figure', '3a', 'find', 'grasp', 'object', 'somewhere', 'vicinity', 'floor', 'table', 'height', 'robot', 'task', 'grasp', 'object', 'using', 'gripper', 'rewarded', 'successfully', 'grasping', 'object', 'penalized', 'unsuccessful', 'grasp', 'moving', 'far', 'away', 'object', 'state', 'space', 'continuous', 'coordinate', 'discrete', 'object', 'height', 'robot', 'us', 'mono', 'camera', 'system', 'object', 'detection', 'hence', 'viewing', 'object', 'single', 'location', 'insufficient', '3d', 'localization', 'moreover', 'initially', 'object', 'might', 'sight', 'robot', 'camera', 'robot', 'must', 'look', 'around', 'first', 'simulation', 'assume', 'general', 'detection', 'error', 'false', 'positive', 'false', 'negative', 'additional', 'gaussian', 'noise', 'object', 'detected', 'correctly', 'robot', 'action', 'include', 'tum', 'variable', 'angle', 'translation', 'variable', 'distance', 'grasp', 'one', 'two', 'legal', 'height', 'robot', 'control', 'erroneous', 'variance', 'space', 'rotational', 'space', 'typical', 'belief', 'state', 'range', 'uniformly', 'distributed', 'sample', 'set', 'initial', 'belief', 'sample', 'narrowly', 'focused', 'specific', 'location', 'thrun', 'figure', 'find', 'fetch', 'task', 'success', 'iteration', 'mobile', 'robot', 'gripper', 'camera', 'holding', 'target', 'object', 'experiment', 'carded', 'simulation', 'three', 'successful', 'run', 'trajectory', 'projected', '2d', 'success', 'rate', 'function', 'number', 'planning', 'step', 'figure', '3c', 'show', 'rate', 'successful', 'grasp', 'function', 'iteration', 'action', 'initially', 'robot', 'fails', 'grasp', 'object', 'approximately', 'iteration', 'perfor', 'mance', 'surpasses', 'planning', 'time', 'order', 'hour', 'however', 'robot', 'fails', 'reach', 'part', 'certain', 'initial', 'configuration', 'make', 'impossible', 'succeed', 'object', 'close', 'maximum', 'allowed', 'distance', 'part', 'robot', 'occasionally', 'miss', 'object', 'centimeter', 'figure', '3b', 'depicts', 'three', 'successful', 'example', 'trajectory', 'three', 'robot', 'initially', 'search', 'object', 'move', 'towards', 'grasp', 'successfully', 'discussion', 'presented', 'monte', 'carlo', 'approach', 'learning', 'act', 'partially', 'observable', 'markov', 'decision', 'process', 'pomdps', 'approach', 'represents', 'belief', 'distribution', 'using', 'sample', 'drawn', 'distribution', 'reinforcement', 'learning', 'belief', 'space', 'applied', 'learn', 'optimal', 'policy', 'using', 'sample', 'based', 'version', 'nearest', 'neighbor', 'generalization', 'backup', 'performed', 'using', 'monte', 'carlo', 'sampling', 'initial', 'experimental', 'result', 'demonstrate', 'approach', 'applicable', 'real', 'valued', 'domain', 'yield', 'good', 'performance', 'result', 'environment', 'pomdp', 'standard', 'relatively', 'large', 'reference', 'aaai', 'fall', 'symposium', 'pomdps', 'see', 'http', 'www', 'duke', 'edu', 'mlittman', 'talk', 'pomdp', 'symposium', 'html', 'bellman', 'dynamic', 'programming', 'princeton', 'university', 'press', 'dayan', 'sejnowski', 'td', 'converges', 'probability', 'fox', 'burgard', 'dellaert', 'thrun', 'monte', 'carlo', 'localization', 'efficient', 'position', 'estimation', 'mobile', 'robot', 'aaai', 'isard', 'ake', 'ndensati', 'nditi', 'na', 'density', 'pr', 'pagati', 'nf', 'visua', 'tracking', 'nternati', 'nalj', 'urnal', 'rnputer', 'vision', 'kaelbling', 'littman', 'cassandra', 'planning', 'acting', 'partially', 'observable', 'stochastic', 'domain', 'submitted', 'publication', 'kaelbling', 'littman', 'moore', 'reinforcement', 'learning', 'survey', 'jair', 'kanazawa', 'koller', 'russell', 'stochastic', 'simulation', 'algorithm', 'dynamic', 'probabilistic', 'network', 'uai', 'lin', 'self', 'improving', 'reactive', 'agent', 'based', 'reinforcement', 'learning', 'planning', 'teaching', 'machine', 'learning', 'littman', 'cassandra', 'kaelbling', 'learning', 'policy', 'partially', 'observable', 'environment', 'scaling', 'icml', 'moore', 'atkeson', 'schaal', 'locally', 'weighted', 'learning', 'control', 'aireview', 'ormoneit', 'sen', 'kernel', 'based', 'reinforcementlearning', 'tr', 'statistic', 'stanford', 'university', 'pitt', 'shephard', 'filtering', 'via', 'simulation', 'auxiliary', 'particle', 'filter', 'journal', 'american', 'statistical', 'association', 'sondik', 'optimal', 'control', 'partially', 'observable', 'markov', 'process', 'phd', 'thesis', 'stanford', 'sutton', 'barto', 'reinforcement', 'learning', 'introduction', 'mit', 'press', 'tanner', 'tool', 'statistical', 'inference', 'springer', 'verlag', 'watkins', 'learning', 'delayed', 'reward', 'phd', 'thesis', 'king', 'college', 'cambridge']]\nWall time: 42 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "    return norm_papers\n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))\n",
    "print(norm_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['connectivity', 'versus', 'entropy', 'yaser', 'abu', 'mostafa', 'california', 'institute', 'technology', 'pasadena', 'ca', 'abstract', 'doe', 'connectivity', 'neural', 'network', 'number', 'synapsis', 'per', 'neuron', 'relate', 'complexity', 'problem', 'handle', 'measured', 'entropy', 'switching', 'theory', 'would', 'suggest', 'relation', 'since', 'boolean', 'function', 'implemented', 'using', 'circuit', 'low', 'connectivity', 'using', 'two', 'input', 'nand', 'gate', 'however', 'network', 'learns', 'problem', 'example', 'using']\n"
    }
   ],
   "source": [
    "# Viewing a processed paper\n",
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['connectivity', 'versus', 'entropy', 'yaser', 'abu_mostafa', 'california_institute', 'technology_pasadena', 'ca_abstract', 'doe', 'connectivity', 'neural_network', 'number', 'synapsis', 'per', 'neuron', 'relate', 'complexity', 'problem', 'handle', 'measured', 'entropy', 'switching', 'theory', 'would', 'suggest', 'relation', 'since', 'boolean_function', 'implemented', 'using', 'circuit', 'low', 'connectivity', 'using', 'two', 'input', 'nand', 'gate', 'however', 'network', 'learns', 'problem', 'example', 'using', 'local', 'learning', 'rule', 'prove', 'entropy', 'problem']\n"
    }
   ],
   "source": [
    "import gensim\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter=b'_')\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "print(bigram_model[norm_papers[0]][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sample word to number mappings: [(0, '0a'), (1, '2h'), (2, '2h2'), (3, '2he'), (4, '2n'), (5, '__c'), (6, '_c'), (7, '_k'), (8, 'a2'), (9, 'ability'), (10, 'abu_mostafa'), (11, 'access'), (12, 'accommodate'), (13, 'according'), (14, 'accumulated')]\nTotal Vocabulary Size: 78892\n"
    }
   ],
   "source": [
    "# Create a dictionary representation of the documents.\n",
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['0a',\n '2h',\n '2h2',\n '2he',\n '2n',\n '__c',\n '_c',\n '_k',\n 'a2',\n 'ability',\n 'abu_mostafa',\n 'access',\n 'accommodate',\n 'according',\n 'accumulated',\n 'acknowledgement_work',\n 'addison_wesley',\n 'afosr',\n 'aip',\n 'air_force',\n 'alently',\n 'also',\n 'although',\n 'american_institute',\n 'amount',\n 'analog',\n 'anyway',\n 'ao',\n 'appears',\n 'appendix',\n 'approximately',\n 'arbitrary',\n 'architecture',\n 'arise',\n 'arned',\n 'aspect',\n 'assume',\n 'assumed',\n 'assumption',\n 'asymptotic',\n 'available',\n 'away',\n 'axe',\n 'basic',\n 'become',\n 'becomes',\n 'benefit',\n 'best',\n 'big',\n 'binary',\n 'biological',\n 'bit',\n 'bit_per',\n 'boolean_function',\n 'bt',\n 'btl',\n 'c0',\n 'ca_abstract',\n 'california_institute',\n 'cannot',\n 'capable',\n 'carried',\n 'case',\n 'cell',\n 'choosing',\n 'circuit',\n 'clearly',\n 'collective',\n 'compare',\n 'complete',\n 'complex',\n 'complexity',\n 'computing',\n 'concept',\n 'conclude',\n 'conference',\n 'connected',\n 'connectivity',\n 'consequence',\n 'consider',\n 'contribution',\n 'convenience',\n 'coordinate',\n 'corresponding',\n 'corresponds',\n 'cto',\n 'define',\n 'defined',\n 'defines',\n 'definition',\n 'denker',\n 'denote',\n 'depending',\n 'depends',\n 'derned',\n 'describes',\n 'designed',\n 'desired',\n 'diagonal',\n 'difference',\n 'different',\n 'directly',\n 'discussing',\n 'disorder',\n 'distinguishability',\n 'distinguishable',\n 'distinguishing',\n 'doe',\n 'doe_depend',\n 'drawn',\n 'ea',\n 'eaei0',\n 'easy',\n 'ed',\n 'edge',\n 'el',\n 'element',\n 'en',\n 'end',\n 'enough',\n 'ensemble',\n 'entire',\n 'entropy',\n 'environmen',\n 'environment',\n 'equiv',\n 'equivalent',\n 'essentially',\n 'estimate',\n 'evaluate',\n 'eventually',\n 'everything',\n 'example',\n 'excludes',\n 'exhaus',\n 'expand',\n 'expected',\n 'exposition',\n 'expression',\n 'extraction',\n 'extreme',\n 'fact',\n 'feature',\n 'final',\n 'find',\n 'finite_automaton',\n 'fir',\n 'first',\n 'fixed',\n 'follows',\n 'fork',\n 'formal',\n 'frequency',\n 'function',\n 'furthermore',\n 'gate',\n 'general',\n 'generate',\n 'generated',\n 'generating',\n 'get',\n 'getting',\n 'given',\n 'global',\n 'go',\n 'go_infinity',\n 'going',\n 'gradually',\n 'graph',\n 'h2',\n 'h2_',\n 'ha',\n 'hand',\n 'handle',\n 'hence',\n 'hi',\n 'hold',\n 'however',\n 'huge',\n 'idea',\n 'ieee_trans',\n 'illustrate',\n 'imple',\n 'implemented',\n 'imposes',\n 'indeed',\n 'independent',\n 'independently',\n 'indistinguishability',\n 'infor',\n 'informal',\n 'information',\n 'input',\n 'interaction',\n 'interested',\n 'internal',\n 'introduce',\n 'introduction',\n 'involved',\n 'irh',\n 'ity',\n 'jl',\n 'jr',\n 'july',\n 'ki',\n 'kind',\n 'know',\n 'knowledge',\n 'kohavi',\n 'label',\n 'large',\n 'last',\n 'le',\n 'learn',\n 'learned',\n 'learning',\n 'learns',\n 'length',\n 'let',\n 'let_denote',\n 'li',\n 'likely',\n 'lim',\n 'limit',\n 'limn',\n 'limn_',\n 'lnl',\n 'loaded',\n 'local',\n 'log',\n 'low',\n 'lower_bound',\n 'main',\n 'make',\n 'mally',\n 'many',\n 'maximum',\n 'may',\n 'mcgraw_hill',\n 'mead',\n 'mean',\n 'measure',\n 'measured',\n 'mechanism',\n 'menting',\n 'merely',\n 'model',\n 'much_smaller',\n 'must',\n 'n2',\n 'nand',\n 'need',\n 'needed',\n 'neither',\n 'network',\n 'neural',\n 'neural_network',\n 'neuron',\n 'next_section',\n 'nl',\n 'nl_n2',\n 'normalized',\n 'notation',\n 'num_ber',\n 'number',\n 'o0',\n 'o1',\n 'object',\n 'obvious',\n 'occur',\n 'occurrence',\n 'office_scientific',\n 'one',\n 'oo',\n 'oos',\n 'opposite',\n 'otherwise',\n 'overall',\n 'paper',\n 'parameter',\n 'part',\n 'particular',\n 'pattern',\n 'per',\n 'perform',\n 'perhaps',\n 'physic',\n 'picture',\n 'pixel',\n 'place',\n 'plausible',\n 'point',\n 'position',\n 'possible',\n 'powerful',\n 'pp',\n 'pr',\n 'pr_pr',\n 'predicts',\n 'principle',\n 'pro_ceedings',\n 'probability',\n 'probability_distribution',\n 'problem',\n 'process',\n 'produce',\n 'program',\n 'projection',\n 'proof',\n 'property',\n 'prove',\n 'provides',\n 'pt',\n 'purposely',\n 'putting',\n 'quantitative',\n 'r2',\n 'r_',\n 'random',\n 'random_variable',\n 'randomness',\n 'range',\n 'rather',\n 'ready',\n 'recall',\n 'reference',\n 'regardless',\n 'relate',\n 'relation',\n 'relative',\n 'replacement',\n 'report',\n 'represented',\n 'research_grant',\n 'respect',\n 'respectively',\n 'restate',\n 'restrict',\n 'restricted',\n 'restriction',\n 'result',\n 'rh',\n 'roughly_speaking',\n 'rt2',\n 'rtl',\n 'rule',\n 'run',\n 'sample',\n 'satifies',\n 'say',\n 'sb',\n 'search',\n 'second',\n 'see',\n 'seen',\n 'selected',\n 'set',\n 'shall',\n 'show',\n 'simulate',\n 'since',\n 'small',\n 'something',\n 'sophisticated',\n 'specifies',\n 'specify',\n 'spon',\n 'start',\n 'starting',\n 'state',\n 'statistic',\n 'statistical',\n 'statistically',\n 'step',\n 'still',\n 'string',\n 'strong',\n 'subset',\n 'substituting',\n 'suggest',\n 'sum',\n 'suppose',\n 'supposed',\n 'switching',\n 'sx',\n 'symmetry',\n 'synapse',\n 'synapsis',\n 'system',\n 'taken',\n 'taneously',\n 'technical',\n 'technology_pasadena',\n 'telabel',\n 'tell',\n 'term',\n 'theorem',\n 'theory',\n 'therefore',\n 'throwing',\n 'thus',\n 'time',\n 'tive',\n 'together',\n 'total',\n 'training',\n 'tune',\n 'twice',\n 'two',\n 'undirected',\n 'uniform',\n 'upper_bound',\n 'us',\n 'use',\n 'used',\n 'using',\n 'v2',\n 'v_l',\n 'va',\n 'val_ues',\n 'value',\n 'variance',\n 'variation',\n 'vat',\n 'vector',\n 'version',\n 'versus',\n 'vertex',\n 'vhat',\n 'view',\n 'vironment',\n 'visual_scene',\n 'vl',\n 'vlsiand',\n 'vol_pp',\n 'wa_supported',\n 'way',\n 'without',\n 'word',\n 'would',\n 'wr',\n 'write',\n 'written',\n 'x2',\n 'x6e',\n 'xi',\n 'xl',\n 'xn',\n 'ya',\n 'yaser',\n 'yx',\n 'zero',\n 'zl',\n '04l',\n '0il',\n '10k',\n '16l',\n '1f_',\n '2e',\n '2k',\n '4x4',\n 'absence',\n 'absolute',\n 'acad_sci',\n 'acc',\n 'accoun',\n 'achieve',\n 'ackley_hinton',\n 'acknowledgment_work',\n 'across',\n 'activation',\n 'adairire',\n 'adaptive',\n 'add',\n 'added',\n 'adding',\n 'addition',\n 'address',\n 'adjacent',\n 'adjust',\n 'adjusting',\n 'adjustment',\n 'adopted',\n 'advance',\n 'advanced_research',\n 'afi',\n 'al',\n 'algorilhm',\n 'algorilhms',\n 'algorithm',\n 'allen',\n 'allows',\n 'almost',\n 'alspec',\n 'alspector',\n 'always',\n 'ame',\n 'americ',\n 'american',\n 'amherst',\n 'amos',\n 'amplifier',\n 'analyzability',\n 'anderson',\n 'andy',\n 'anneal',\n 'annealing',\n 'annealing_schedule',\n 'another',\n 'answer',\n 'aplaroach',\n 'applied',\n 'approach',\n 'approximation',\n 'area',\n 'arnin',\n 'arranged',\n 'arrangement',\n 'array',\n 'artificial_neural',\n 'aside',\n 'associative_memory',\n 'assure',\n 'asynchronous',\n 'asynchronously',\n 'ation',\n 'attached',\n 'attack',\n 'attempt',\n 'average',\n 'averaged',\n 'avoid',\n 'avoiding',\n 'ay',\n 'back',\n 'bandwidth',\n 'banu',\n 'barto',\n 'barto_sutton',\n 'based',\n 'basis',\n 'bearing',\n 'behavior',\n 'believe',\n 'bell',\n 'bellcore',\n 'bentc',\n 'berkeley',\n 'berkeley_ca',\n 'better',\n 'bi',\n 'biologically',\n 'bipolar',\n 'bldg',\n 'block_diagram',\n 'bly',\n 'bollzmann',\n 'boltzmann',\n 'boltzmann_machine',\n 'book',\n 'bottom',\n 'brain',\n 'branch',\n 'califomia',\n 'called',\n 'cambridge',\n 'capacitance',\n 'capacitor',\n 'cauch',\n 'cauchy',\n 'caught',\n 'ccd',\n 'cforgelting',\n 'ch',\n 'chance',\n 'change',\n 'channel',\n 'characteristic',\n 'characterize',\n 'characterized',\n 'charge',\n 'chip',\n 'choice',\n 'chose',\n 'chosen',\n 'cij',\n 'circ',\n 'circuilry',\n 'clamp',\n 'clamping',\n 'classification',\n 'clj',\n 'close',\n 'closest',\n 'cluster',\n 'cmony',\n 'cmos',\n 'cmos_technology',\n 'co',\n 'coding',\n 'cognition_vol',\n 'cognitive_science',\n 'cohen_grossberg',\n 'coin',\n 'collected',\n 'columbia',\n 'column',\n 'com',\n 'comer',\n 'communication',\n 'compact',\n 'compared',\n 'comparison',\n 'compatible',\n 'compete',\n 'competition',\n 'competitive',\n 'competitive_learning',\n 'complementarity',\n 'complementary',\n 'completed',\n 'component',\n 'compressing',\n 'comprifive',\n 'computation',\n 'computational',\n 'computer_simulation',\n 'conclusion',\n 'condition',\n 'conductance',\n 'connect',\n 'connection',\n 'connection_strength',\n 'connects',\n 'considered',\n 'consisted',\n 'consists',\n 'constant',\n 'continuous',\n 'contrast',\n 'contributing',\n 'control',\n 'controlled',\n 'controlling',\n 'controued',\n 'convention',\n 'converging',\n 'convert',\n 'cooccurrence',\n 'cooccurrences',\n 'corn',\n 'correct',\n 'correct_answer',\n 'correction',\n 'correlated',\n 'correlating',\n 'correlation',\n 'correlational',\n 'correspond',\n 'correspondence',\n 'could',\n 'count',\n 'counter',\n 'counting',\n 'coupled',\n 'cq',\n 'creates',\n 'credit_assignment',\n 'criterion',\n 'critic',\n 'cuits',\n 'cumulative',\n 'current',\n 'currently',\n 'curten',\n 'cut',\n 'cyber',\n 'cycle',\n 'cyhemetics',\n 'czamul',\n 'damp',\n 'dc',\n 'de',\n 'decay',\n 'decide',\n 'decrease',\n 'decreased',\n 'decrement',\n 'decremented',\n 'ded',\n 'deign',\n 'demonstrate',\n 'department',\n 'dependence',\n 'dependent',\n 'describe',\n 'described',\n 'design',\n 'determines',\n 'deterministic',\n 'developed',\n 'development',\n 'device',\n 'differential',\n 'differs',\n 'difficult',\n 'diffusion',\n 'digital',\n 'dipole',\n 'directed',\n 'discovering',\n 'discovery',\n 'discrele',\n 'discussion',\n 'dispute',\n 'dissertation',\n 'distribution',\n 'diverse',\n 'divide',\n 'divided',\n 'division',\n 'dliams',\n 'doctoral',\n 'domain',\n 'dominance',\n 'double',\n 'due',\n 'duster',\n 'dynamic',\n 'earning',\n 'ease',\n 'easily',\n 'ections',\n 'edited',\n 'ee',\n 'eeprom',\n 'effect',\n 'effective',\n 'effectively',\n 'efficient',\n 'effort',\n 'eider',\n 'either',\n 'elation',\n 'electric',\n 'electron',\n 'electronic',\n 'electronically',\n 'electronics',\n 'elemenl',\n 'elucidating',\n 'emanating',\n 'embellishing',\n 'emergent_collective',\n 'employed',\n 'ended',\n 'engineer',\n 'enmti',\n 'ent',\n 'envision',\n 'eplication',\n 'eprom',\n 'eq',\n 'equal',\n 'er',\n 'ere',\n 'error',\n 'es',\n 'especially',\n 'essential',\n 'evaluation',\n 'even',\n 'exceeded',\n 'except',\n 'excess',\n 'excites',\n 'expense',\n 'experiment',\n 'explicit',\n 'exploration_microstructure',\n 'explored',\n 'exponentially',\n 'ext',\n 'extended',\n 'externally',\n 'ey',\n 'f_',\n 'factor',\n 'family',\n 'favorable',\n 'feature_detector',\n 'fed',\n 'feedback',\n 'fet',\n 'ff',\n 'fi',\n 'fig',\n 'figure',\n 'finally',\n 'finding',\n 'fions',\n 'fition',\n 'fitive',\n 'flip_flop',\n 'floating',\n 'fmhman',\n 'follow',\n 'following',\n 'form',\n 'formation',\n 'formulalion',\n 'foundation',\n 'fourth',\n 'fraction',\n 'free',\n 'freq',\n 'fully',\n 'functionality',\n 'fundamental',\n 'future',\n 'gain',\n 'gale',\n 'gannett',\n 'gaussian',\n 'gaussian_noise',\n 'gave',\n 'generalize_well',\n 'geoffrey_hinton',\n 'get_stuck',\n 'give',\n 'glob',\n 'global_optimization',\n 'globally',\n 'goal',\n 'good',\n 'graded',\n 'gradient',\n 'greater',\n 'grossberg',\n 'guaranteed',\n 'guidance',\n 'guided',\n 'gupta',\n 'hall',\n 'hart',\n 'hastic',\n 'havior',\n 'hebb',\n 'hebbian',\n 'help',\n 'helped',\n 'helping',\n 'hidden_unit',\n 'high',\n 'highly',\n 'hint',\n 'hinton',\n 'histogram',\n 'hope',\n 'hopefully',\n 'hopfield',\n 'horizontally',\n 'howev',\n 'htdden',\n 'hut',\n 'i2',\n 'ide',\n 'identify',\n 'ii',\n 'ij',\n 'ill',\n 'illustrated',\n 'illustrated_fig',\n 'implement',\n 'implementable',\n 'implementation',\n 'implementing',\n 'importam',\n 'important',\n 'improve',\n 'improvement',\n 'include',\n 'includes',\n 'incomplete',\n 'increase',\n 'increasingly',\n 'increment',\n 'incremented',\n 'individual',\n 'influenced',\n 'inherent',\n 'inhibition',\n 'inhibito',\n 'iniorj',\n 'initially',\n 'inpul',\n 'inset',\n 'insisting',\n 'inst',\n 'instead',\n 'integrated',\n 'integrated_circuit',\n 'integrator',\n 'interconnected',\n 'interesting',\n 'internal_representation',\n 'interpolate',\n 'inverse',\n 'inverter',\n 'invesfgated',\n 'isj',\n 'issue',\n 'j_',\n 'ji',\n 'jitter',\n 'jlttsr',\n 'joel',\n 'josh',\n 'joshua',\n 'keeping',\n 'lamb',\n 'lambe',\n 'larger',\n 'lastly',\n 'later',\n 'latter',\n 'layer',\n 'layout',\n 'lea_ming',\n 'leading',\n 'leaky',\n 'leaming',\n 'led',\n 'left',\n 'lett',\n 'level',\n 'liapunov',\n 'like',\n 'like_thank',\n 'lime',\n 'line',\n 'linear',\n 'lo',\n 'local_minimum',\n 'locally',\n 'logarithmic',\n 'logic',\n 'long',\n 'long_term',\n 'looking',\n 'losleben',\n 'low_pas',\n 'low_power',\n 'lower',\n 'm1t',\n 'machine',\n 'magnitude',\n 'mahowald_mead',\n 'maitra',\n 'major',\n 'making',\n 'man',\n 'manipulated',\n 'mass',\n 'matched',\n 'matrix',\n 'maximization',\n 'mclu',\n 'mcr',\n 'mcrment',\n 'mealing',\n 'memory',\n 'mentioned',\n 'merit',\n 'method',\n 'mghest',\n 'mhy',\n 'micron',\n 'microscopic',\n 'microvolt',\n 'might',\n 'millionfold',\n 'minimum',\n 'minus',\n 'miracle',\n 'mit_press',\n 'mjt',\n 'mm',\n 'mnos',\n 'mo',\n 'modeling',\n 'modifying',\n 'molecular',\n 'moopenn',\n 'moreover',\n 'morristown',\n 'mosfefs',\n 'mosfets',\n 'moved',\n 'moving',\n ...]"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "list(dictionary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Vocabulary Size: 7756\n"
    }
   ],
   "source": [
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(3, 1), (12, 3), (14, 1), (15, 1), (16, 1), (17, 16), (20, 1), (24, 1), (26, 1), (31, 3), (35, 1), (36, 1), (40, 3), (41, 5), (42, 1), (48, 1), (53, 3), (55, 1), (56, 2), (58, 1), (60, 3), (63, 5), (64, 4), (65, 2), (73, 1), (74, 1), (75, 1), (76, 1), (77, 3), (82, 1), (83, 4), (84, 1), (85, 1), (86, 2), (94, 1), (96, 2), (97, 3), (106, 1), (110, 1), (119, 2), (120, 4), (121, 2), (124, 2), (127, 1), (128, 1), (132, 1), (133, 1), (135, 6), (136, 1), (144, 1)]\n"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('ability', 1), ('aip', 3), ('although', 1), ('american_institute', 1), ('amount', 1), ('analog', 16), ('appears', 1), ('architecture', 1), ('aspect', 1), ('available', 3), ('become', 1), ('becomes', 1), ('binary', 3), ('biological', 5), ('bit', 1), ('cannot', 1), ('circuit', 3), ('collective', 1), ('compare', 2), ('complex', 1), ('computing', 3), ('conference', 5), ('connected', 4), ('connectivity', 2), ('define', 1), ('defined', 1), ('defines', 1), ('definition', 1), ('denker', 3), ('designed', 1), ('desired', 4), ('diagonal', 1), ('difference', 1), ('directly', 2), ('ed', 1), ('el', 2), ('element', 3), ('equivalent', 1), ('eventually', 1), ('feature', 2), ('final', 4), ('find', 2), ('fixed', 2), ('frequency', 1), ('furthermore', 1), ('generating', 1), ('get', 1), ('global', 6), ('go', 1), ('hence', 1)]\n"
    }
   ],
   "source": [
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1740"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "len(bow_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LATENT SEMANTIC INDEXING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_TOPICS = 10\n",
    "lsi_bow = gensim.models.LsiModel(bow_corpus, id2word=dictionary, num_topics=TOTAL_TOPICS, onepass=True, chunksize=1740, power_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Topic #1:\n0.215*\"unit\" + 0.212*\"state\" + 0.187*\"training\" + 0.177*\"neuron\" + 0.162*\"pattern\" + 0.145*\"image\" + 0.140*\"vector\" + 0.125*\"feature\" + 0.122*\"cell\" + 0.110*\"layer\" + 0.101*\"task\" + 0.097*\"class\" + 0.091*\"probability\" + 0.089*\"signal\" + 0.087*\"step\" + 0.086*\"response\" + 0.085*\"representation\" + 0.083*\"noise\" + 0.082*\"rule\" + 0.081*\"distribution\"\n\nTopic #2:\n0.487*\"neuron\" + 0.396*\"cell\" + -0.257*\"state\" + 0.191*\"response\" + -0.187*\"training\" + 0.170*\"stimulus\" + 0.117*\"activity\" + -0.109*\"class\" + 0.099*\"spike\" + 0.097*\"pattern\" + 0.096*\"circuit\" + 0.096*\"synaptic\" + -0.095*\"vector\" + 0.090*\"signal\" + 0.090*\"firing\" + 0.088*\"visual\" + -0.084*\"classifier\" + -0.083*\"action\" + -0.078*\"word\" + 0.078*\"cortical\"\n\nTopic #3:\n0.627*\"state\" + -0.395*\"image\" + 0.219*\"neuron\" + -0.209*\"feature\" + 0.188*\"action\" + -0.137*\"unit\" + -0.131*\"object\" + 0.130*\"control\" + -0.129*\"training\" + 0.109*\"policy\" + -0.103*\"classifier\" + -0.090*\"class\" + 0.081*\"step\" + 0.081*\"dynamic\" + -0.080*\"classification\" + -0.078*\"layer\" + -0.076*\"recognition\" + 0.074*\"reinforcement_learning\" + -0.069*\"representation\" + -0.068*\"pattern\"\n\nTopic #4:\n-0.686*\"unit\" + 0.433*\"image\" + -0.182*\"pattern\" + -0.131*\"layer\" + -0.123*\"hidden_unit\" + -0.121*\"net\" + -0.114*\"training\" + 0.112*\"feature\" + -0.109*\"activation\" + -0.107*\"rule\" + 0.097*\"neuron\" + -0.078*\"word\" + 0.070*\"pixel\" + -0.070*\"connection\" + 0.067*\"object\" + 0.065*\"state\" + 0.060*\"distribution\" + 0.059*\"face\" + -0.057*\"architecture\" + 0.055*\"estimate\"\n\nTopic #5:\n0.428*\"image\" + 0.348*\"state\" + -0.266*\"neuron\" + 0.264*\"unit\" + -0.181*\"training\" + -0.174*\"class\" + 0.168*\"object\" + -0.167*\"classifier\" + 0.147*\"action\" + 0.122*\"visual\" + -0.117*\"vector\" + -0.115*\"node\" + -0.105*\"distribution\" + 0.103*\"motion\" + 0.099*\"feature\" + -0.097*\"classification\" + 0.097*\"control\" + 0.095*\"task\" + 0.087*\"cell\" + 0.083*\"representation\"\n\nTopic #6:\n-0.660*\"cell\" + 0.508*\"neuron\" + 0.213*\"image\" + 0.103*\"chip\" + 0.097*\"unit\" + -0.093*\"response\" + 0.090*\"object\" + -0.083*\"rat\" + -0.076*\"distribution\" + 0.070*\"circuit\" + -0.069*\"probability\" + -0.064*\"stimulus\" + 0.061*\"memory\" + 0.058*\"analog\" + 0.058*\"activation\" + -0.055*\"class\" + 0.053*\"bit\" + 0.052*\"net\" + -0.051*\"cortical\" + -0.050*\"firing\"\n\nTopic #7:\n0.353*\"word\" + -0.281*\"unit\" + 0.272*\"training\" + 0.257*\"classifier\" + 0.177*\"recognition\" + -0.159*\"distribution\" + 0.152*\"feature\" + 0.144*\"state\" + 0.142*\"pattern\" + -0.141*\"vector\" + 0.128*\"cell\" + 0.128*\"task\" + -0.122*\"approximation\" + -0.121*\"variable\" + -0.110*\"equation\" + 0.107*\"classification\" + -0.106*\"noise\" + 0.103*\"class\" + -0.101*\"matrix\" + 0.098*\"neuron\"\n\nTopic #8:\n0.303*\"pattern\" + -0.243*\"signal\" + -0.236*\"control\" + -0.202*\"training\" + 0.181*\"rule\" + 0.178*\"state\" + -0.167*\"noise\" + 0.166*\"class\" + -0.162*\"word\" + 0.155*\"cell\" + 0.154*\"feature\" + -0.147*\"motion\" + -0.140*\"task\" + 0.127*\"node\" + 0.124*\"neuron\" + -0.116*\"target\" + -0.114*\"circuit\" + 0.114*\"probability\" + 0.110*\"classifier\" + 0.109*\"image\"\n\nTopic #9:\n-0.472*\"node\" + -0.254*\"circuit\" + 0.214*\"word\" + -0.201*\"chip\" + 0.190*\"neuron\" + 0.172*\"stimulus\" + -0.160*\"classifier\" + -0.152*\"current\" + 0.147*\"feature\" + -0.146*\"voltage\" + 0.145*\"distribution\" + -0.141*\"control\" + -0.124*\"rule\" + -0.110*\"layer\" + -0.105*\"analog\" + -0.091*\"tree\" + 0.084*\"response\" + 0.080*\"state\" + 0.079*\"probability\" + 0.079*\"estimate\"\n\nTopic #10:\n-0.518*\"word\" + 0.254*\"training\" + -0.236*\"vector\" + 0.222*\"task\" + 0.194*\"pattern\" + 0.156*\"classifier\" + -0.149*\"node\" + -0.146*\"recognition\" + 0.139*\"control\" + -0.138*\"sequence\" + 0.126*\"rule\" + -0.125*\"circuit\" + -0.123*\"cell\" + 0.113*\"action\" + 0.105*\"neuron\" + -0.094*\"hmm\" + -0.093*\"character\" + -0.088*\"chip\" + -0.088*\"matrix\" + -0.085*\"structure\"\n\n"
    }
   ],
   "source": [
    "for topic_id, topic in lsi_bow.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Topic #1:\n==================================================\nDirection 1: [('unit', 0.215), ('state', 0.212), ('training', 0.187), ('neuron', 0.177), ('pattern', 0.162), ('image', 0.145), ('vector', 0.14), ('feature', 0.125), ('cell', 0.122), ('layer', 0.11), ('task', 0.101), ('class', 0.097), ('probability', 0.091), ('signal', 0.089), ('step', 0.087), ('response', 0.086), ('representation', 0.085), ('noise', 0.083), ('rule', 0.082), ('distribution', 0.081)]\n--------------------------------------------------\nDirection 2: []\n--------------------------------------------------\n\nTopic #2:\n==================================================\nDirection 1: [('neuron', 0.487), ('cell', 0.396), ('response', 0.191), ('stimulus', 0.17), ('activity', 0.117), ('spike', 0.099), ('pattern', 0.097), ('circuit', 0.096), ('synaptic', 0.096), ('signal', 0.09), ('firing', 0.09), ('visual', 0.088), ('cortical', 0.078)]\n--------------------------------------------------\nDirection 2: [('state', -0.257), ('training', -0.187), ('class', -0.109), ('vector', -0.095), ('classifier', -0.084), ('action', -0.083), ('word', -0.078)]\n--------------------------------------------------\n\nTopic #3:\n==================================================\nDirection 1: [('state', 0.627), ('neuron', 0.219), ('action', 0.188), ('control', 0.13), ('policy', 0.109), ('step', 0.081), ('dynamic', 0.081), ('reinforcement_learning', 0.074)]\n--------------------------------------------------\nDirection 2: [('image', -0.395), ('feature', -0.209), ('unit', -0.137), ('object', -0.131), ('training', -0.129), ('classifier', -0.103), ('class', -0.09), ('classification', -0.08), ('layer', -0.078), ('recognition', -0.076), ('representation', -0.069), ('pattern', -0.068)]\n--------------------------------------------------\n\nTopic #4:\n==================================================\nDirection 1: [('image', 0.433), ('feature', 0.112), ('neuron', 0.097), ('pixel', 0.07), ('object', 0.067), ('state', 0.065), ('distribution', 0.06), ('face', 0.059), ('estimate', 0.055)]\n--------------------------------------------------\nDirection 2: [('unit', -0.686), ('pattern', -0.182), ('layer', -0.131), ('hidden_unit', -0.123), ('net', -0.121), ('training', -0.114), ('activation', -0.109), ('rule', -0.107), ('word', -0.078), ('connection', -0.07), ('architecture', -0.057)]\n--------------------------------------------------\n\nTopic #5:\n==================================================\nDirection 1: [('image', 0.428), ('state', 0.348), ('unit', 0.264), ('object', 0.168), ('action', 0.147), ('visual', 0.122), ('motion', 0.103), ('feature', 0.099), ('control', 0.097), ('task', 0.095), ('cell', 0.087), ('representation', 0.083)]\n--------------------------------------------------\nDirection 2: [('neuron', -0.266), ('training', -0.181), ('class', -0.174), ('classifier', -0.167), ('vector', -0.117), ('node', -0.115), ('distribution', -0.105), ('classification', -0.097)]\n--------------------------------------------------\n\nTopic #6:\n==================================================\nDirection 1: [('neuron', 0.508), ('image', 0.213), ('chip', 0.103), ('unit', 0.097), ('object', 0.09), ('circuit', 0.07), ('memory', 0.061), ('analog', 0.058), ('activation', 0.058), ('bit', 0.053), ('net', 0.052)]\n--------------------------------------------------\nDirection 2: [('cell', -0.66), ('response', -0.093), ('rat', -0.083), ('distribution', -0.076), ('probability', -0.069), ('stimulus', -0.064), ('class', -0.055), ('cortical', -0.051), ('firing', -0.05)]\n--------------------------------------------------\n\nTopic #7:\n==================================================\nDirection 1: [('word', 0.353), ('training', 0.272), ('classifier', 0.257), ('recognition', 0.177), ('feature', 0.152), ('state', 0.144), ('pattern', 0.142), ('cell', 0.128), ('task', 0.128), ('classification', 0.107), ('class', 0.103), ('neuron', 0.098)]\n--------------------------------------------------\nDirection 2: [('unit', -0.281), ('distribution', -0.159), ('vector', -0.141), ('approximation', -0.122), ('variable', -0.121), ('equation', -0.11), ('noise', -0.106), ('matrix', -0.101)]\n--------------------------------------------------\n\nTopic #8:\n==================================================\nDirection 1: [('pattern', 0.303), ('rule', 0.181), ('state', 0.178), ('class', 0.166), ('cell', 0.155), ('feature', 0.154), ('node', 0.127), ('neuron', 0.124), ('probability', 0.114), ('classifier', 0.11), ('image', 0.109)]\n--------------------------------------------------\nDirection 2: [('signal', -0.243), ('control', -0.236), ('training', -0.202), ('noise', -0.167), ('word', -0.162), ('motion', -0.147), ('task', -0.14), ('target', -0.116), ('circuit', -0.114)]\n--------------------------------------------------\n\nTopic #9:\n==================================================\nDirection 1: [('word', 0.214), ('neuron', 0.19), ('stimulus', 0.172), ('feature', 0.147), ('distribution', 0.145), ('response', 0.084), ('state', 0.08), ('probability', 0.079), ('estimate', 0.079)]\n--------------------------------------------------\nDirection 2: [('node', -0.472), ('circuit', -0.254), ('chip', -0.201), ('classifier', -0.16), ('current', -0.152), ('voltage', -0.146), ('control', -0.141), ('rule', -0.124), ('layer', -0.11), ('analog', -0.105), ('tree', -0.091)]\n--------------------------------------------------\n\nTopic #10:\n==================================================\nDirection 1: [('training', 0.254), ('task', 0.222), ('pattern', 0.194), ('classifier', 0.156), ('control', 0.139), ('rule', 0.126), ('action', 0.113), ('neuron', 0.105)]\n--------------------------------------------------\nDirection 2: [('word', -0.518), ('vector', -0.236), ('node', -0.149), ('recognition', -0.146), ('sequence', -0.138), ('circuit', -0.125), ('cell', -0.123), ('hmm', -0.094), ('character', -0.093), ('chip', -0.088), ('matrix', -0.088), ('structure', -0.085)]\n--------------------------------------------------\n\n"
    }
   ],
   "source": [
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    for term, wt in lsi_bow.show_topic(n, topn=20):\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((7756, 10), (10,), (10, 1740))"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "term_topic = lsi_bow.projection.u\n",
    "singular_values = lsi_bow.projection.s\n",
    "topic_document = (gensim.matutils.corpus2dense(lsi_bow[bow_corpus], len(singular_values)).T / singular_values).T\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n0  0.016  0.017  0.013  0.008 -0.024  0.028 -0.000  0.019  0.008  0.006\n1  0.041  0.030  0.019 -0.021 -0.019  0.056 -0.018 -0.009 -0.018  0.011\n2  0.022 -0.000  0.022  0.008 -0.011  0.016 -0.013  0.017  0.001 -0.007\n3  0.032  0.036  0.011 -0.014 -0.035  0.052  0.016  0.043  0.010  0.029\n4  0.035 -0.002  0.017 -0.008 -0.016  0.017 -0.032  0.022 -0.050 -0.029",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>T1</th>\n      <th>T2</th>\n      <th>T3</th>\n      <th>T4</th>\n      <th>T5</th>\n      <th>T6</th>\n      <th>T7</th>\n      <th>T8</th>\n      <th>T9</th>\n      <th>T10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.016</td>\n      <td>0.017</td>\n      <td>0.013</td>\n      <td>0.008</td>\n      <td>-0.024</td>\n      <td>0.028</td>\n      <td>-0.000</td>\n      <td>0.019</td>\n      <td>0.008</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.041</td>\n      <td>0.030</td>\n      <td>0.019</td>\n      <td>-0.021</td>\n      <td>-0.019</td>\n      <td>0.056</td>\n      <td>-0.018</td>\n      <td>-0.009</td>\n      <td>-0.018</td>\n      <td>0.011</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.022</td>\n      <td>-0.000</td>\n      <td>0.022</td>\n      <td>0.008</td>\n      <td>-0.011</td>\n      <td>0.016</td>\n      <td>-0.013</td>\n      <td>0.017</td>\n      <td>0.001</td>\n      <td>-0.007</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.032</td>\n      <td>0.036</td>\n      <td>0.011</td>\n      <td>-0.014</td>\n      <td>-0.035</td>\n      <td>0.052</td>\n      <td>0.016</td>\n      <td>0.043</td>\n      <td>0.010</td>\n      <td>0.029</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.035</td>\n      <td>-0.002</td>\n      <td>0.017</td>\n      <td>-0.008</td>\n      <td>-0.016</td>\n      <td>0.017</td>\n      <td>-0.032</td>\n      <td>0.022</td>\n      <td>-0.050</td>\n      <td>-0.029</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3),\n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_topics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Document #13:\nDominant Topics (top 3): ['T3', 'T8', 'T9']\nPaper Summary:\n137 \nOn the \nPower of Neural Networks for \nSolving Hard Problems \nJehoshua Bruck \nJoseph W. Goodman \nInformation Systems Laboratory \nDepartment of Electrical Engineering \nStanford University \nStanford, CA 94305 \nAbstract \nThis paper deals with a neural network model in which each neuron \nperforms a threshold logic function. An important property of the model \nis that it always converges to a stable state when operating in a serial \nmode [2,5]. This property is the basis of the potential applicat\n\nDocument #250:\nDominant Topics (top 3): ['T9', 'T8', 'T1']\nPaper Summary:\n542 Kassebaum, Tenorio and Schaefers \nThe Cocktail Party Problem: \nSpeech/Data Signal Separation Comparison \nbetween Backpropagation and SONN \nJohn Kassebaum \njakec.ecn.purdue.edu \nManoel Fernando Tenorio \ntenorioee.ecn.purdue.edu \nChrlstoph Schaefers \nParallel Distributed Structures Laboratory \nSchool of Electrical Engineering \nPurdue University \nW. Lafayette, IN. 47907 \nABSTRACT \nThis work introduces a new method called Self Organizing Neural \nNetwork (SONN) algorithm and compares its perfor\n\nDocument #500:\nDominant Topics (top 3): ['T1', 'T10', 'T7']\nPaper Summary:\nLearning Global Direct Inverse Kinematics \nDavid DeMers* \nComputer Science & Eng. \nUC San Diego \nLa Jolla, CA 92093-0114 \nKenneth Kreutz-Deigado I \nElectrical & Computer Eng. \nUC San Diego \nLa Jolla, CA 92093-0407 \nAbstract \nWe introduce and demonstrate a bootstrap method for construction of an in- \nverse function for the robot kinematic mapping using only sample configuration- \nspace/workspace data. Unsupervised learning (clustering) techniques are used on \npre-image neighborhoods in order to l\n\n"
    }
   ],
   "source": [
    "document_numbers = [13, 250, 500]\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.columns[np.argsort(-\n",
    "                                               np.absolute(\n",
    "                                          document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(7756, 1740)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[4., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# LSI from scratch\n",
    "td_matrix = gensim.matutils.corpus2dense(corpus=bow_corpus, num_terms=len(dictionary))\n",
    "print(td_matrix.shape)\n",
    "td_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740, alpha=\"auto\", eta=\"auto\", random_state=42, iterations=500, num_topics=TOTAL_TOPICS, passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU 1.14",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}